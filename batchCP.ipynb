{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Import TensorLy\n",
    "# import tensorly as tl\n",
    "# from tensorly.tucker_tensor import tucker_to_tensor\n",
    "# from tensorly.random import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/media/rich/Home_Linux_partition/github_repos/tensorly')\n",
    "\n",
    "import tensorly as tl\n",
    "import tensorly.decomposition\n",
    "import tensorly.random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux-5.4.0-54-generic-x86_64-with-glibc2.10\n",
      "Python 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "NumPy 1.19.2\n",
      "SciPy 1.5.2\n",
      "TensorLy 0.5.0\n",
      "PyTorch 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import tensorly; print(\"TensorLy\", tensorly.__version__)\n",
    "import torch; print(\"PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 1234\n",
    "rng = tensorly.random.check_random_state(random_state)\n",
    "num_cpuCores = len(os.sched_getaffinity(0))\n",
    "# device = 'cuda' if torch.cuda.device_count() > 0 else 'cpu'\n",
    "device = 'cuda:0'\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [3]: torch.cuda.device(0)\n",
    "Out[3]: <torch.cuda.device at 0x7efce0b03be0>\n",
    "\n",
    "In [4]: torch.cuda.device_count()\n",
    "Out[4]: 1\n",
    "\n",
    "In [5]: torch.cuda.get_device_name(0)\n",
    "Out[5]: 'GeForce GTX 950M'\n",
    "\n",
    "In [6]: torch.cuda.is_available()\n",
    "Out[6]: True\n",
    "    \n",
    "torch.device\n",
    "# device = 'cpu'\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### import data\n",
    "\n",
    "# dir_factors_np = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run3'\n",
    "# fileName_factors_np = f'factors_np.npy'\n",
    "# path_factors_np = f'{dir_factors_np}/{fileName_factors_np}'\n",
    "# factors_np = np.load(path_factors_np , allow_pickle=True)\n",
    "# print(f'inputTensor shape: {factors_np.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import data\n",
    "\n",
    "dir_inputTensor = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run2'\n",
    "fileName_inputTensor = f'Sxx_allPixels.npy'\n",
    "path_inputTensor = f'{dir_inputTensor}/{fileName_inputTensor}'\n",
    "inputTensor = np.load(path_inputTensor)\n",
    "# inputTensor = torch.tensor(inputTensor , device=device)\n",
    "# inputTensor = torch.tensor(inputTensor , device='cpu').pin_memory()\n",
    "inputTensor = torch.tensor(inputTensor , dtype=tl.float32 , requires_grad=False)\n",
    "# inputTensor = inputTensor\n",
    "print(f'inputTensor shape: {inputTensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tensor = tl.tensor(inputTensor[:,:,:4500, :] , device=device , dtype=tl.float32 , requires_grad=True)\n",
    "# tensor = torch.tensor(inputTensor[:,:,:4500, :] , device=device , dtype=tl.float32 , requires_grad=True)\n",
    "# # tensor = tl.tensor(tensor[ , device=device , requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gc\n",
    "\n",
    "del inputTensor\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_toUse = 8\n",
    "ranks = [rank_toUse , rank_toUse, rank_toUse , rank_toUse]\n",
    "# core = tl.tensor(rng.random_sample(ranks), device=device, requires_grad=True)\n",
    "\n",
    "# factors = [tl.tensor(rng.random_sample((tensor.shape[i], ranks[i])),\n",
    "#                  device=device, requires_grad=True) for i in range(tl.ndim(tensor))]\n",
    "\n",
    "weights = tl.tensor(np.ones(rank_toUse) , device=device, dtype=tl.float32, requires_grad=True)\n",
    "# weights = tl.tensor(np.ones(rank_toUse) , device=\"cuda:0\", dtype=tl.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "   \n",
    "### Make dataset objects\n",
    "\n",
    "class make_batchSlices_dataObj(Dataset):\n",
    "    def __init__(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tensor (tensor type): for now, this is a variable (in the memory) that should be pre-loaded in\n",
    "        \"\"\"\n",
    "        self.tensor_full = input_tensor\n",
    "    def __len__(self):\n",
    "        return self.tensor_full.shape[2]\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()        \n",
    "#         tensor_slice = torch.tensor( self.tensor_full[:,:,idx,:] , dtype=torch.float32 , device=device , requires_grad=True )\n",
    "#         tensor_slice = self.tensor_full[:,:,idx,:]\n",
    "#         tensor_slice = torch.tensor(self.tensor_full[:,:,idx,:] , device=device , dtype=torch.float32 , requires_grad=True)\n",
    "#         return tensor_slice , idx\n",
    "        return idx\n",
    "    \n",
    "# class make_batchFilaments_dataObj(Dataset):\n",
    "#     def __init__(self, input_tensor):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             input_tensor (tensor type): for now, this is a variable (in the memory) that should be pre-loaded in\n",
    "#         \"\"\"\n",
    "#         self.tensor_full = input_tensor\n",
    "#         self.shape_tensor = self.tensor_full.shape\n",
    "#     def __len__(self):\n",
    "#         return self.shape_tensor[0] * self.shape_tensor[1] * self.shape_tensor[3]\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()     \n",
    "#         idx_subscripts = np.unravel_index([idx], (batchFilaments_dataObj.shape_tensor[0] , batchFilaments_dataObj.shape_tensor[1] , batchFilaments_dataObj.shape_tensor[3]) , order='F') # order='F' necessary to make it (dim 0 , dim1 , dim2, ...)\n",
    "#         idx_subscripts = np.array(idx_subscripts)[:,0]\n",
    "        \n",
    "#         tensor_filament = torch.tensor( self.tensor_full[idx_subscripts[0],idx_subscripts[1],:,idx_subscripts[2]] , dtype=torch.float32 , device=device , requires_grad=True )\n",
    "#         return tensor_filament , idx , idx_subscripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "    \n",
    "batch_size = int(np.floor(inputTensor.shape[2]/ 20))\n",
    "\n",
    "batchSlices_dataObj = make_batchSlices_dataObj(inputTensor)\n",
    "dataloader_batchSlices = DataLoader(batchSlices_dataObj, batch_size=batch_size, drop_last=True\n",
    "                        , shuffle=True\n",
    "#                         , num_workers=num_cpuCores\n",
    "                        , num_workers=0\n",
    "#                         , pin_memory=True\n",
    "#                         , collate_fn=lambda x: default_collate(x).to(device) \n",
    "                                   )\n",
    "\n",
    "# batchFilaments_dataObj = make_batchFilaments_dataObj(inputTensor)\n",
    "# dataloader_batchFilaments = DataLoader(batchFilaments_dataObj, batch_size=1, drop_last=True,\n",
    "#                         shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#basic libary\n",
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "# torch.multiprocessing.set_start_method('spawn')# good solution !!!!\n",
    "\n",
    "##Define Function and class to be used\n",
    "eps = 1.3e-7  # Slightly higher than min value of fp32\n",
    "prox_plus = nn.Threshold(0,eps) ## to make all output postive \n",
    "\n",
    "class NTF(nn.Module): ## Model\n",
    "    def __init__(self):\n",
    "        super(NTF, self).__init__()\n",
    "\n",
    "#         self.factors = nn.ParameterList([nn.Parameter(torch.tensor(rng.random_sample((tensor.shape[i], ranks[i])) , device='cuda:0').double(), requires_grad=True) for i in range(tensor.ndim)])\n",
    "        \n",
    "#         self.factors = [tl.tensor(rng.random_sample((tensor.shape[i], ranks[i])), device='cuda:0', requires_grad=True) for i in range(tl.ndim(tensor))]\n",
    "\n",
    "           \n",
    "        self.factors1 = nn.Parameter(torch.tensor(rng.random_sample((inputTensor.shape[0], ranks[0])) , dtype=tl.float32 , device=device), requires_grad=True) \n",
    "        self.factors2 = nn.Parameter(torch.tensor(rng.random_sample((inputTensor.shape[1], ranks[1])) , dtype=tl.float32 , device=device), requires_grad=True) \n",
    "        self.factors3 = nn.Parameter(torch.tensor(rng.random_sample((inputTensor.shape[2], ranks[2])) , dtype=tl.float32 , device=device), requires_grad=True) \n",
    "        self.factors4 = nn.Parameter(torch.tensor(rng.random_sample((inputTensor.shape[3], ranks[3])) , dtype=tl.float32 , device=device), requires_grad=True) \n",
    "        \n",
    "    def forward(self , idx):\n",
    "#             tmp = list((self.factors3.relu() , self.factors1.relu() , self.factors2.relu() , self.factors4.relu()))\n",
    "#             tmp = list((self.factors3[idx,:].relu() , self.factors1.relu() , self.factors2.relu() , self.factors4.relu()))\n",
    "#             tmp = list((self.factors3[idx,:] , self.factors1 , self.factors2 , self.factors4))\n",
    "#         tmp = list((prox_plus(self.factors3[idx,:]) , prox_plus(self.factors1) , prox_plus(self.factors2) , prox_plus(self.factors4)))\n",
    "        tmp = list( (prox_plus(self.factors1) , prox_plus(self.factors2) , prox_plus(self.factors3[idx,:]) ,prox_plus(self.factors4)) )\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "#         reconstruction = prox_plus(tl.cp_tensor.cp_to_tensor((weights, tmp)))\n",
    "        reconstruction = tl.cp_tensor.cp_to_tensor((weights, tmp))\n",
    "        return reconstruction\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "print('Start training on Task 1...')\n",
    "# plt.figure()\n",
    "\n",
    "ntf_obj = NTF()\n",
    "ntf_obj.cuda()\n",
    "loss_rolling=[] #collect loss\n",
    "\n",
    "n_epoch =5000\n",
    "# lr = 0.005\n",
    "# lr = 0.02\n",
    "lr_batch = 0.04\n",
    "lr_nonBatch = 0.04\n",
    "penalty_L1 = 0.1\n",
    "penalty_L2 = 0.1\n",
    "weight_decay = 0.05\n",
    "# loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(((ntf_obj.factors1, ntf_obj.factors2 , ntf_obj.factors3 , ntf_obj.factors4)),  lr=lr)\n",
    "optimizer_batchParam    = torch.optim.Adam([ntf_obj.factors3]  ,  lr=lr_batch , weight_decay=weight_decay)\n",
    "optimizer_nonBatchParams    = torch.optim.Adam(((ntf_obj.factors1, ntf_obj.factors2 , ntf_obj.factors4))  ,  lr=lr_nonBatch , weight_decay=weight_decay)\n",
    "num_repeats_per_batch = 10\n",
    "\n",
    "length_factors3 = ntf_obj.factors3.shape[0]\n",
    "for epoch in range(n_epoch):\n",
    "#     torch.cuda.empty_cache()\n",
    "    ntf_obj.factors1.requires_grad = True\n",
    "    ntf_obj.factors2.requires_grad = True\n",
    "    ntf_obj.factors3.requires_grad = True\n",
    "    ntf_obj.factors4.requires_grad = True\n",
    "#     for iter_batchSlices , (tensor_batchSlices, idx_batchSlices)   in   enumerate(dataloader_batchSlices):\n",
    "    optimizer_nonBatchParams.zero_grad() # need to clear the old gradients\n",
    "    for iter_batchSlices , idx_batchSlices   in   enumerate(dataloader_batchSlices):\n",
    "        idx_batchSlices_bool = np.in1d(np.arange(length_factors3) , idx_batchSlices)\n",
    "        factors3_frozen = ntf_obj.factors3.clone().detach()\n",
    "        tensor_batchSlices = inputTensor[:,:,idx_batchSlices,:].to(device)\n",
    "        \n",
    "        for iter_repeats in range(num_repeats_per_batch):\n",
    "            optimizer_batchParam.zero_grad() # need to clear the old gradients\n",
    "            Y_ = ntf_obj(idx_batchSlices)\n",
    "            loss = tl.norm((Y_ - tensor_batchSlices), 2)\n",
    "#             loss = tl.norm(Y_ - tensor_batchSlices, 2)\n",
    "#             # squared l2 penalty on the factors of the decomposition\n",
    "#             for param in ntf_obj.parameters():\n",
    "#         #         loss = loss + penalty_L2 * param.data.pow(2).sum()\n",
    "#         #         loss = loss + penalty_L2 * param.data.abs().sum()\n",
    "#                 l1_regularization = penalty_L1 * torch.norm(param.data, 1)\n",
    "#                 l2_regularization = penalty_L2 * (torch.norm(param.data, 2)**2)\n",
    "#                 loss = loss + l1_regularization + l2_regularization\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            loss_rolling.append(loss.detach())\n",
    "            optimizer_batchParam.step()\n",
    "        if(iter_batchSlices%5==0):\n",
    "    #         print(loss)\n",
    "    #         print(f'loss = {loss.cpu().detach().numpy()[None][0]}')\n",
    "    #             rec_error = loss/tl.norm(goal_tensor, 2)\n",
    "    #         rec_error = loss/tl.norm(val, 2)\n",
    "            rec_error = 0\n",
    "    #             print(\"Epoch {}  ,  Rec. error: {}  ,  loss: {}\".format(epoch, rec_error, loss))\n",
    "            clear_output()\n",
    "            plt.plot(loss_rolling)\n",
    "            plt.show()\n",
    "            plt.plot(loss_rolling[-2000:])\n",
    "            plt.show()\n",
    "            print(\"Epoch: {}  ,  Batch position: {}/{}  ,  Repeat Num: {}  Rec. error: {}  ,  loss: {}\".format(epoch+1, iter_batchSlices+1 , length_factors3/batch_size , iter_repeats , rec_error , loss))\n",
    "        with torch.no_grad():\n",
    "            ntf_obj.factors3[~idx_batchSlices_bool,:] = factors3_frozen[~idx_batchSlices_bool,:]\n",
    "    optimizer_nonBatchParams.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ntf_obj.factors3[~idx_batchSlices_bool,:] = factors3_frozen[~idx_batchSlices_bool,:]\n",
    "\n",
    "factors_np = list(np.zeros(4))\n",
    "for ii , param in enumerate(ntf_obj.parameters()):\n",
    "    factors_np[ii] = param.relu().cpu().detach().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(loss_rolling[1:])\n",
    "plt.ylabel('loss over time')\n",
    "plt.xlabel('repeat (sub-iteration) #')\n",
    "plt.show()\n",
    "\n",
    "print('Final loss on Task 1: ')\n",
    "print(loss_rolling[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(factors_np[0])\n",
    "plt.figure()\n",
    "plt.plot(factors_np[1])\n",
    "plt.figure()\n",
    "plt.plot(factors_np[2])\n",
    "plt.figure()\n",
    "plt.plot(factors_np[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val[0].clone().detach().to(device).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pca_lowrank(test[:,:,:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:,:,:1000,:]**22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun\n",
    "for ii in range(3):\n",
    "    for ii , val in enumerate(dataloader_batchSlices):\n",
    "        test = val[0].clone().detach().to(device).requires_grad_(True)\n",
    "        print(ii)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
