{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1> Joint Factorization </h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "This is a developmental notebook for performing joint factorizations between neural and behavioral data. We assume you've run Face Rhythm to completion. Start by copying your config filepath to this variable, we'll be using it for the rest of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "from face_rhythm.util import helpers\n",
    "\n",
    "config_filepath = ''# Fill the complete path to your config file here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1> Face with Neural Trace </h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "Here's the necessary code for producing face with neural trace videos. We'll add more code for doing the joint factorization within Face Rhythm above... later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest and re-align factors\n",
    "\n",
    "For this version of the code, we provisionally assume you can provide us with: \n",
    "1. A path to an alignment file that has the time series for the neural data and a time series of the camera video \n",
    "2. A path to a 'joint factors' h5 file that has all the factors for all the different alphas tested \n",
    "3. An alpha index that you want to use for creating videos\n",
    "\n",
    "This code chunk will save an upsampled, re-aligned temporal factor with a corresponding face factor to the Face Rhythm NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_rhythm.neural import align\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['Neural']['alignment_file_path'] = '' \n",
    "config['Neural']['joint_factor_path'] = '' \n",
    "config['Neural']['alpha_ind'] = 0 \n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "align.video_prep_wrapper(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Face with Trace Code\n",
    "For this code chunk, we expect that you provide us: \n",
    "1. The type of factors that you'll be plotting (usually either TCA, PCA, or Neural)\n",
    "2. The name of the face factor (in this case, just 'factors_spatial')\n",
    "3. The name of the temporal factor (in this case, just 'factors_temporal')\n",
    "4. The name of the points to plot (taken from the Face Rhythm NWB)\n",
    "\n",
    "We also have a bunch of other settings for the face with trace including things like the frame that you want to start on, the length of the video, the size of the dots, the number of factors to plot, etc. \n",
    "\n",
    "Give it a second to run! There are a lot of moving parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_rhythm.visualize import videos\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['Video']['factor_category_to_display'] = 'Neural' # eg: 'TCA' or 'PCA' or 'Neural'\n",
    "config['Video']['face_factor_to_display'] = 'factors_spatial' # eg: 'factors_spectral_points'\n",
    "config['Video']['temporal_factor_to_display'] = 'factors_temporal' # eg: 'factors_spectral_temporal'\n",
    "config['Video']['points_to_display'] = 'positions_convDR_absolute' # eg: 'positions_convDR_absolute' or 'positions_absolute' or 'positions_recursive'\n",
    "\n",
    "config['Video']['start_vid'] = 0 # 0 indexed\n",
    "config['Video']['start_frame'] = 1000 # 0 indexed\n",
    "config['Video']['demo_len'] = 1000\n",
    "config['Video']['dot_size'] = 2\n",
    "config['Video']['save_demo'] = True \n",
    "config['Video']['factors_to_show'] = [1] # 1 indexed, if this is empty, plots all factors\n",
    "config['Video']['show_alpha'] = True # changes intensity of the colors along with temporal trace\n",
    "config['Video']['pulse_test_index'] = 0 # if this is nonzero, it will add a pulse and blackout to check syncing\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "videos.face_with_trace(config_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face-rhythm] *",
   "language": "python",
   "name": "conda-env-face-rhythm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
