{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Face Rhythm</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1wcz_8-cq6MppJ_wkOOu7GkeZkYI3uGB1\">\n",
    "\n",
    "***\n",
    "\n",
    "##### Notebook Shortcuts\n",
    "- **[Notebook Setup](#Notebook-Setup)**: Prepare all the necessary config files and folders\n",
    "- **[Set ROI](#Set-ROI)**: Set the ROI for the analysis\n",
    "- **[Run Optic Flow](#Run-Optic-Flow)**: Run the optic flow analysis\n",
    "- **[Clean Optic Flow](#Clean-Optic-Flow)**: Optic flow post-processing\n",
    "- **[Convolutional Dimensionality Reduction](#Convolutional-Dimensionality-Reduction)**: Convolutional Dimensionality Reduction\n",
    "- **[Analysis](#Analysis)**: Decompose and Analyze the optic flow data in many ways\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tips on running this notebook:\n",
    "In theory it would be nice if you could just enter the path of the video(s) and just let it run all the way through. In practice, there are a few hoops to jump through\n",
    "- Run the Notebook Setup Block (two blocks below this one). This should pretty much always be done, even if you are loading precomputed file from disk instead of calculating them. This step loads in some useful meta data used throughout.\n",
    "- Even if you are restarting at a specific point in your analysis, run your Setup Block then head down to your current analysis step cell \n",
    "- There are two options for calculating the optic flow (parameters set independently as well), one single-threaded and one multi-threaded. Do parameter tuning on the single-threaded one so you can quit out of it, as well as watch the calculation as it happens with showVideo_pref=1. The multi-threaded one is only faster if you have a lot of cores in your CPU (>10), then it's faster, else stick with the single-threaded version and set showVideo_pref=0.\n",
    "\n",
    "### The most important parameters:  \n",
    "***(Consider all of these before you run the code for the first time)***\n",
    "- Optic flow params:\n",
    "    - **'spacing'**: ~ 3 to 12. Spacing between dots, in pixels. Inversely related to number of dots to use in the calculation. Try to keep the number of dots below 2000 if possible (eats up memory and computation time). More dots generally means better final results, more robust to outliers and weird stuff. I'd make the spacing as small (more dots) as you can go before you run out of RAM in the final calculations\n",
    "    - **lk_params 'win_size'**: ~ 25,25 to 80,80. This is the spatial integration window for the optical flow measurement. Try to make it as small as possible without it becoming unstable. The two values are for X and Y length of square integration window. Probably keep the same for most applications\n",
    "- Outlier removal params:\n",
    "    - **outlier_threshold_positions**: ~ 20 to 100. If a dot strays more than this many pixels away from its anchor position, its displacement in the dimension it cross the threshold in, for those time points (and some time points around it, see params below), for that dot only, will be set to zero\n",
    "    - **outlier_threshold_displacements** ~ 5 to 25. Similar to above, but for displacement. Only the outlier time points are removed (no window around outliers considered).\n",
    "    - **framesHalted_beforeOutlier**: ~ 0 to 30. The number of frames to also remove before detected outlier events. Consider what is causing your outlier event. If it is an arm movement or something, how long does such a movement last? How long before it will cause a dot to move to the outlier threshold?\n",
    "    - **framesHalted_afterOutlier**: ~ 0 to 10. Simlar to above but for after an outlier event is detected\n",
    "    - **relaxation_factor** : ~ 0.03 to 0.1. This is the rate of the exponential decay / relaxation / attraction back to the anchor position that a point undergoes. It is meant to prevent baseline drift. Think of it like a high pass on the dot position trace\n",
    "- Spectral analysis params:\n",
    "    - **win_len**: ~ 0.1 to 1.0. The length of the time window used for the short-time Fourier transform. Longer gives better spectral resolution, shorter gives better temporal resolution. There are several other parameters that are related but this is the most important. Longer windows (along with decreasing the overlap parameter) also decrease the size of the output spectrograms, which can help with memory and computation time in the subsequent analyses\n",
    "- TCA:\n",
    "    - **rank = 6**: ~ 2 to 10. The number of factors to look for in the PARAFAC model. More can be good but less reproduceable, but less can mix together obviously different factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Notebook Setup</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Creates config and locates videos\n",
    "\n",
    "**Crucially, always run this first cell every time you run this notebook.**\n",
    "\n",
    "Also, generally make sure to read through the config parameters before running.\n",
    "\n",
    "The Project path is the path to a folder (existing or not) where we will store our derived files. I recommend creating a project folder and then copying this notebook into that folder.\n",
    "The Video path is the path to the folder with all the raw videos. \n",
    "The run name will determine the name of the config. You might create multiple configs if you want to re-run the same data with slightly different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Organization Assumptions\n",
    "We assume that you have s Sessions and v Videos per session. For some users, there will only be one video per session. You might have multiple videos per session because either (1) you save your session video in chunks due to your recording software or (2) you have separated your video into _trial_ videos. If your videos correspond to discrete trials, mark the trials option True. If you have a single video per session with a _trial_ structure, you should also provide a _trial_indexes_ file. We'll need this to properly run optic flow on it. \n",
    "\n",
    "If your Data Folder contains folder you don't want, you can specify a folder name pattern to restrict the folders considered.\n",
    "\n",
    "- Data Folder\n",
    "   - Session Folder 1\n",
    "      - Video 1\n",
    "      - ...\n",
    "      - Video v\n",
    "      - Optional: trial_indexes\n",
    "   - ...\n",
    "   - Session Folder s\n",
    "      - Video 1\n",
    "      - ...\n",
    "      - Video v\n",
    "      - Optional: trial_indexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ALWAYS RUN THIS CELL\n",
    "# widen jupyter notebook window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))\n",
    "\n",
    "# Import libraries\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.cuda\n",
    "\n",
    "from face_rhythm.util import helpers\n",
    "from pathlib import Path\n",
    "\n",
    "# SET THE PROJECT PATH, DATA PATH, and (optionally) run name\n",
    "project_path     = Path('./').resolve()\n",
    "video_path       = Path('../../data').resolve()\n",
    "run_name         = 'new'\n",
    "overwrite_config = False\n",
    "remote           = False # cv2 doesn't play nicely with ssh/slurm connections, set true if using that\n",
    "trials           = True  # Let us know if you're using trials\n",
    "\n",
    "config_filepath = helpers.setup_project(project_path, video_path, run_name, overwrite_config, remote, trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import types\n",
    "from pathlib import Path\n",
    "# IMPORT VIDEOS\n",
    "# We handle the session_prefix tag cleverly\n",
    "# If you specify a unique folder, then we'll just load just one folder\n",
    "# If you specify a folder prefix, then we'll load all sessions that fit that prefix\n",
    "# If you specify no prefix, then we'll load all sessions\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['Video']['session_prefix'] = 'hr047' \n",
    "config['Video']['print_filenames'] = True\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "helpers.import_videos(config_filepath)\n",
    "helpers.get_video_data(config_filepath)\n",
    "helpers.create_nwbs(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>Set ROI</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Manually specify your roi\n",
    "\n",
    "This is good if your animal doesn't fill the view and if you have stationary objects nearby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from face_rhythm.util import helpers\n",
    "from face_rhythm.util import set_roi\n",
    "\n",
    "### Select POLYGON SUBFRAME for DISPLACEMENT Eignfaces\n",
    "## This block of code will pop up a little GUI. Click around the\n",
    "## region of the face that you want to include in the analysis.\n",
    "## When you are done, click the 'Disconnect mpl' button\n",
    "\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['ROI']['session_to_set'] = 'hr047'\n",
    "config['ROI']['vid_to_set'] = 1 # 1 indexed. Sets the video to use to make an image\n",
    "config['ROI']['frame_to_set'] = 2 # 1 indexed. Sets the frame number to use to make an image\n",
    "config['ROI']['load_from_file'] = False\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "frame, bbox_selector = set_roi.get_roi(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this until you're done selecting\n",
    "if not config['ROI']['load_from_file']:\n",
    "    set_roi.process_roi(config_filepath, frame, bbox_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Run Optic Flow</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Run as either single- or multi-threaded depending on run time and number of dots\n",
    "\n",
    "Multithread is generally 2X to many-X faster, but may fail when too many dots are selected (memory overload)\n",
    "\n",
    "*If show video set to true on a remote connection, the video won't show, but it will save to the proj folder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from face_rhythm.optic_flow import optic_flow\n",
    "\n",
    "### == PREFERENCES ==\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "config['Optic']['sessions_to_use'] = [0]\n",
    "config['Optic']['spacing'] = 8  ## This is the distance between points in the grid (both in x and y dims)\n",
    "\n",
    "config['Optic']['show_video'] = True  ## much faster when video is off. If 'remote' option chosen (from first cell block), video will be saved as file in project folder.\n",
    "config['Optic']['test_len'] = 10 # used only for remote users when show_video==True\n",
    "config['Optic']['dot_size'] = 1  ## for viewing purposes\n",
    "\n",
    "## below will print the fps ever 'fps_counterPeriod' . Useful for checking the approximate speed of import.\n",
    "## Best to turn off when doing a full run. (this is mostly for optimizing and debugging)\n",
    "config['Optic']['print_fps'] = False\n",
    "config['Optic']['fps_counterPeriod'] = 10 ## number of frames to do a tic toc over\n",
    "\n",
    "## Parameters for lucas kanade optical flow\n",
    "## win size: spatial integration window (make small as possible, but make bigger if youre having issues with outliers)\n",
    "## max level: only moderate effects if everything working properly. Keep around 3.\n",
    "## criteria values have to do with the search algorithm. For speed: EPS small, COUNT big.\n",
    "config['Optic']['lk'] = {}\n",
    "config['Optic']['lk']['winSize']     = (30,30)\n",
    "config['Optic']['lk']['maxLevel']    = 4\n",
    "config['Optic']['lk']['criteria']    = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.001)\n",
    "\n",
    "config['Optic']['recursive'] = True\n",
    "config['Optic']['relaxation_factor'] = 0.001\n",
    "config['Optic']['multithread'] = False \n",
    "\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "\n",
    "### == CALCULATION ==\n",
    "\n",
    "optic_flow.optic_workflow(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Clean Optic Flow</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Clean up displacements traces and make good positions traces\n",
    "\n",
    "Check the parameters here, they are essential for getting good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from face_rhythm.optic_flow import clean_results\n",
    "\n",
    "## Create position trace from displacements\n",
    "## This block does a few things:\n",
    "\n",
    "## 1. Finds outliers: These are currently defined as time points when the integrated position goes beyond some threshold.\n",
    "##  Note that since displacements are calculated for x and y separately, outlier events are also separated into x outlier events\n",
    "##  and y outlier events.\n",
    "\n",
    "## 2. Sets displacements during outlier events to ZERO: There are some parameters below that define the time window (in frames)\n",
    "##  before and after outliers to also set to zero. Note again, that DISPLACEMENT (the derivative of position) is set to zero, \n",
    "##  effectively pausing the position of the ingegrated position.\n",
    "\n",
    "## 3. Rectifies the position to its 'anchor position': I am defining position as the integrated displacement arising from a STATIC\n",
    "##  place in the image. Because this analysis is image agnostic, drift naturally occurs. This term counteracts drift by simply\n",
    "##  relaxing each dot's position back to the center of its displacement analysis window. This term should be as low as possible\n",
    "##  because it also acts as a high pass filter, thus precluding analysis of slow timescale changes.\n",
    "\n",
    "## Note that using a standard frequency filter (fir, iir) here for the rectification / relaxation doesn't work well\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['outlier_threshold_positions'] = 30 ## in pixels. If position goes past this, short time window before and including outlier timepoint has displacement set to 0 \n",
    "config['outlier_threshold_displacements'] = 4 ## in pixels. If displacement goes past this, displacement set to 0 at those time points\n",
    "config['framesHalted_beforeOutlier'] = 20 # in frames. best to make even\n",
    "config['framesHalted_afterOutlier'] = 4 # in frames. best to make even\n",
    "config['relaxation_factor'] = 0.001 # This is the speed at which the integrated position exponentially relaxes back to its anchored position. Make ~0.005 to 0.05 for face video at 120 Hz\n",
    "config['pixelNum_toPlot'] = 10\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "clean_results.clean_workflow(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>Convolutional Dimensionality Reduction</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Do some denoising and to get the number of dots down to a managable number\n",
    "\n",
    "In particular, it is nice for the batched CP decomposition later that the batches can be as big as possible in the temporal dimension, so doing some mild convolutional dim reduction first is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from face_rhythm.optic_flow import conv_dim_reduce\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "pointInds_toUse = helpers.load_data(config_filepath, 'path_pointInds_toUse')\n",
    "\n",
    "# Create kernel\n",
    "config['cdr_width_cosKernel'] = 12 # This is the radius of a 2-dimensional cosine kernel. If you get an error about SVD not working, probably increase this\n",
    "config['cdr_num_dots'] = pointInds_toUse.shape[0]\n",
    "\n",
    "# Distance between points in the grid\n",
    "config['cdr_spacing'] = 8 \n",
    "\n",
    "# For displaying dots\n",
    "config['cdr_vidNum'] = 0 # 0 indexed\n",
    "config['cdr_frameNum'] = 0 # 0 indexed\n",
    "config['cdr_dot_size'] = 1\n",
    "\n",
    "# Coefficients of influence \n",
    "config['cdr_num_components'] = 4\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "conv_dim_reduce.conv_dim_reduce_workflow(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display or Save video of dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_dim_reduceim_reduce.display_displacements(config_filepath , )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>Analysis</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Decompose and Analyze the Data in different ways\n",
    "\n",
    "Below you'll find the following:\n",
    "- PCA done on raw positions\n",
    "- Spectral analysis of every pixels to transoform the basis to be oscillatory\n",
    "- TCA done on the spectra\n",
    "- A lonely t-SNE plot of the temporal factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "The X and Y displacements are concatenated and run together. Something interesting to try would be to transform to polar coordinates, concatenate and run that way. Maybe TCA on the positions with magnitude vs angle being one of the dimensions would make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from face_rhythm.analysis import pca\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "pca.pca_workflow(config_filepath, 'positions_absolute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.analysis import tca\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### Prepare Tensorly\n",
    "# If the input is small ( < half the size of your GPU memory) and you have CUDA, set to 'gpu'. It's super fast.\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['tca_pref_useGPU'] = False\n",
    "\n",
    "if config['tca_pref_useGPU']:\n",
    "    cuda_device_number = torch.cuda.current_device()\n",
    "    print(f\"using CUDA device: 'cuda:{cuda_device_number}'\")\n",
    "    device = f'cuda:{cuda_device_number}'\n",
    "else:\n",
    "    print(f\"using CPU\")\n",
    "    device = 'cpu'  \n",
    "\n",
    "config['tca_device'] = device\n",
    "config['tca_rank'] = 4\n",
    "config['tca_init'] = 'random'\n",
    "config['tca_vid_display'] = False\n",
    "config['tca_vid_save'] = True\n",
    "positional_path = project_path / 'viz' / 'positional'\n",
    "positional_path.mkdir(parents=True, exist_ok=True)\n",
    "config['tca_vid_dir'] = str(positional_path)\n",
    "config['tca_verbosity'] = 0\n",
    "config['tca_n_iters'] = 100\n",
    "config['tca_display_frames'] = 100\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "tca.positional_tca_workflow(config_filepath, 'positions','positions_absolute') # you can use differe positions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Analysis\n",
    "I've played with a few different methods. While multiresolution methods seems ideal for this use-case, It just ends up severly overrepresenting low frequency factors, making noisier high frequency factors, and doing an overall worse job at reconstruction.\n",
    "A good ol' multitaper short time fourier transform seems to work fine. Adding in raw positions to subsequent dimensionality reduction later on seems like a natural thing to do, as single resolution spectral analysis ends up kind of ignoring slower dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Prepare Tensorly\n",
    "# If the input is small ( < half the size of your GPU memory) and you have CUDA, set to 'gpu'. It's super fast.\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "eps = 1.19209e-07 # float32 epsilon\n",
    "\n",
    "hop_length = 16\n",
    "fmin_rough = 2\n",
    "Fs = config['vid_Fs']\n",
    "sr = Fs\n",
    "n_bins = 50\n",
    "bins_per_octave = int(np.round((n_bins) / np.log2( (Fs/2)/fmin_rough )))\n",
    "fmin = ( (Fs/2)/(2**((n_bins)/bins_per_octave)) ) - (2*eps)\n",
    "fmax = fmin*(2**((n_bins)/bins_per_octave))\n",
    "\n",
    "freqs_Sxx = fmin*(2**((np.arange(n_bins)+1)/bins_per_octave))\n",
    "\n",
    "print(f'bins_per_octave: {round(bins_per_octave)} bins/octave')\n",
    "print(f'minimum frequency (fmin): {round(fmin,3)} Hz')\n",
    "print(f'maximum frequency (fmax): {round(fmax,8)} Hz')\n",
    "print(f'Nyquist                 : {sr/2} Hz')\n",
    "print(f'number of frequencies:    {n_bins} bins')\n",
    "plt.figure()\n",
    "plt.plot(freqs_Sxx)\n",
    "print(f'Frequencies: {np.round(freqs_Sxx , 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.analysis import spectral_analysis\n",
    "\n",
    "### Parameters for multitaper short-time Fourier transform\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['cqt_hop_length'] = hop_length\n",
    "config['cqt_sr'] = sr\n",
    "config['cqt_n_bins'] = n_bins\n",
    "config['cqt_bins_per_octave'] = bins_per_octave\n",
    "config['cqt_fmin'] = fmin\n",
    "config['cqt_fmin_rough'] = fmin_rough\n",
    "config['cqt_fmax'] = fmax\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "helpers.save_data(config_filepath, 'freqs_Sxx', freqs_Sxx)\n",
    "\n",
    "# CQT spectrogram for every pixel\n",
    "# this code was previously parallelized, \n",
    "# but it's pretty quick compared to the other steps, \n",
    "# so might as well keep it simple\n",
    "\n",
    "spectral_analysis.cqt_all(config_filepath, 'positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.analysis import spectral_analysis\n",
    "\n",
    "# Positional CQT\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['cqt_hop_length'] = 8\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "spectral_analysis.cqt_positions(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TCA\n",
    "There are two major tensor packages, one is tensortools (made by an acquaintance named Alex Williams) and the other is Tensorly.\n",
    "Tensorly seems to be more packaged up and has some options to use some advanced backends like torch, tf, and mxnet. Though there are\n",
    "a couple of nice features in tensortools that Tensorly doesn't have, though. Generally tensortools gives better reconstructions, but takes\n",
    "much longer to do it.\n",
    "\n",
    "This function also spits out a ton of plots, consult Rich or Akshay for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from face_rhythm.analysis import tca\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "### Prepare Tensorly\n",
    "\n",
    "# If the input is small ( < half the size of your GPU memory) and you have CUDA, set to 'gpu'. It's super fast.\n",
    "\n",
    "config['tca_pref_useGPU'] = True\n",
    "\n",
    "if config['tca_pref_useGPU']:\n",
    "    cuda_device_number = torch.cuda.current_device()\n",
    "    print(f\"using CUDA device: 'cuda:{cuda_device_number}'\")\n",
    "    device = f'cuda:{cuda_device_number}'\n",
    "else:\n",
    "    print(f\"using CPU\")\n",
    "    device = 'cpu'  \n",
    "\n",
    "config['tca_device'] = device\n",
    "config['tca_rank'] = 8\n",
    "config['tca_vid_display'] = True\n",
    "config['tca_vid_save'] = True\n",
    "path_frequential = project_path / 'viz' / 'frequential'\n",
    "path_frequential.mkdir(parents=True, exist_ok=True)\n",
    "config['tca_vid_dir'] = str(path_frequential)\n",
    "config['tca_verbosity'] = 1\n",
    "config['tca_n_iters'] = 100\n",
    "config['tca_display_frames'] = 500\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "tca.full_tca_workflow(config_filepath, 'positions_absolute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs:\n",
    "Below is the output tree structure of the NWB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.dump_nwb(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how to access NWB output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynwb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "nwb_path = config['path_nwb']\n",
    "io = pynwb.NWBHDF5IO(nwb_path, 'r')\n",
    "nwbfile = io.read()\n",
    "\n",
    "example_data = nwbfile.processing['Face Rhythm']['Optic Flow']['positions'].data\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(example_data[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how to access parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = helpers.load_config(config_filepath)\n",
    "print(config['lk_winSize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face-rhythm] *",
   "language": "python",
   "name": "conda-env-face-rhythm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 957.188,
   "position": {
    "height": "40px",
    "left": "1725.67px",
    "right": "20px",
    "top": "124.914px",
    "width": "628.438px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
