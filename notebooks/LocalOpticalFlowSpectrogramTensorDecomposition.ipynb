{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Face Rhythm</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=14bN4PKuwZQORI_A1wK9r6ZV4_QpZL_L2\">\n",
    "\n",
    "This notebook calculates Face Rhythm. It's dope\n",
    "\n",
    "***\n",
    "\n",
    "##### Notebook Shortcuts\n",
    "- **[Notebook Setup](#Notebook-Setup)**: Prepare all the necessary config files and folders\n",
    "- **[Set ROI](#Set-ROI)**: Set the ROI for the analysis\n",
    "- **[Run Optic Flow](#Run-Optic-Flow)**: Run the optic flow analysis\n",
    "- **[Clean Optic Flow](#Clean-Optic-Flow)**: Optic flow post-processing\n",
    "- **[Analysis](#Analysis)**: Decompose and Analyze the optic flow data in many ways\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tips on running this notebook:\n",
    "In theory it would be nice if you could just enter the path of the video(s) and just let it run all the way through. In practice, there are a few hoops to jump through\n",
    "- Run the import cell block (two blocks below this one). This should pretty much always be done, even if you are loading precomputed file from disk instead of calculating them. This step loads in some useful meta data used throughout.\n",
    "- Use the Save and Load cell blocks to save and load data after long calculations. It seriously helps with iterating, debugging, and memory allocation.\n",
    "    - These arrays can be BIG. I regularly go past 128 GB when running my data through. It's often easiest to just restart the kernel, load in just the precomputed variables needed and run the script in the middle (skipping all the previous computations)\n",
    "- There are two cell blocks for calculating the optic flow (parameters set independently as well), one single-threaded and one multi-threaded. Do parameter tuning on the single-threaded one so you can quit out of it, as well as watch the calculation as it happens with showVideo_pref=1. The multi-threaded one is only faster if you have a lot of cores in your CPU (>10), then it's faster, else stick with the single-threaded version and set showVideo_pref=0.\n",
    "- Parameter tuning should be pretty easy. Most of the cell blocks can be halted in the middle of computation so you can just look at a small bit of the data, tune a parameter and then rerun the code\n",
    "\n",
    "### The most important parameters:  \n",
    "***(Consider all of these before you run the code for the first time)***\n",
    "- Optic flow params:\n",
    "    - **'spacing'**: ~ 3 to 12. Spacing between dots, in pixels. Inversely related to number of dots to use in the calculation. Try to keep the number of dots below 2000 if possible (eats up memory and computation time). More dots generally means better final results, more robust to outliers and weird stuff. I'd make the spacing as small (more dots) as you can go before you run out of RAM in the final calculations\n",
    "    - **lk_params 'win_size'**: ~ 25,25 to 80,80. This is the spatial integration window for the optical flow measurement. Try to make it as small as possible without it becoming unstable. The two values are for X and Y length of square integration window. Probably keep the same for most applications\n",
    "- Outlier removal params:\n",
    "    - **outlier_threshold_positions**: ~ 20 to 100. If a dot strays more than this many pixels away from its anchor position, its displacement in the dimension it cross the threshold in, for those time points (and some time points around it, see params below), for that dot only, will be set to zero\n",
    "    - **outlier_threshold_displacements** ~ 5 to 25. Similar to above, but for displacement. Only the outlier time points are removed (no window around outliers considered).\n",
    "    - **framesHalted_beforeOutlier**: ~ 0 to 30. The number of frames to also remove before detected outlier events. Consider what is causing your outlier event. If it is an arm movement or something, how long does such a movement last? How long before it will cause a dot to move to the outlier threshold?\n",
    "    - **framesHalted_afterOutlier**: ~ 0 to 10. Simlar to above but for after an outlier event is detected\n",
    "    - **relaxation_factor** : ~ 0.03 to 0.1. This is the rate of the exponential decay / relaxation / attraction back to the anchor position that a point undergoes. It is meant to prevent baseline drift. Think of it like a high pass on the dot position trace\n",
    "- Spectral analysis params:\n",
    "    - **win_len**: ~ 0.1 to 1.0. The length of the time window used for the short-time Fourier transform. Longer gives better spectral resolution, shorter gives better temporal resolution. There are several other parameters that are related but this is the most important. Longer windows (along with decreasing the overlap parameter) also decrease the size of the output spectrograms, which can help with memory and computation time in the subsequent analyses\n",
    "- TCA:\n",
    "    - **rank = 6**: ~ 2 to 10. The number of factors to look for in the PARAFAC model. More can be good but less reproduceable, but less can mix together obviously different factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# widen jupyter notebook window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# The only non-publicly available function is mtaper_specgram\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "\n",
    "import scipy\n",
    "import scipy.signal\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.decomposition\n",
    "import skimage.draw\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#sys.path.insert(0, '/media/rich/Home_Linux_partition1/github_repos/tensorly')\n",
    "\n",
    "import tensorly as tl\n",
    "import tensorly.decomposition\n",
    "import tensorly.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Notebook Setup</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Creates config and locates videos\n",
    "\n",
    "As always, make sure to read through the config parameters before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create config and check the code versioning\n",
    "from face_rhythm.util import helpers\n",
    "from pathlib import Path\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "base_dir = Path('./').resolve()\n",
    "config_filepath = base_dir / 'config.yaml'\n",
    " \n",
    "helpers.generate_config(config_filepath) \n",
    "helpers.version_check(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.util import helpers\n",
    "\n",
    "### IMPORT VIDEOS\n",
    "## Define DIRECTORY of video(s) to use and IMPORT videos (as read objects) into openCV\n",
    "## Be careful to follow input the directories properly below. Input directory\n",
    "## and file name (or file name prefix) in either the m\n",
    "\n",
    "# This option imports all of the videos with a defined file name prefix in a folder\n",
    "# OR just imports a single defined file\n",
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "config['multiple_files_pref'] = False\n",
    "config['dir_vid'] = str(Path('../data/').resolve())\n",
    "\n",
    "# Used only if 'multiple_files_pref'==1\n",
    "config['fileName_vid_prefix'] = 'cam3_2020-11-02-185732-' \n",
    "config['fileName_vid_numDigitsInIteration'] = 4 # number of digits in the movie (used when movie is broken up into chunks)\n",
    "config['fileName_vid_suffix'] = '.avi'\n",
    "\n",
    "# Used only if 'multiple_files_pref'==0\n",
    "config['fileName_vid'] = 'raw/gmou06_082720_faceTrack_session1.avi'\n",
    "\n",
    "\n",
    "### == IMPORT videos ==\n",
    "config['print_fileNames_pref'] = 1\n",
    "\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "helpers.import_videos(config_filepath)\n",
    "h# Step 1: Set Up\n",
    "\n",
    "### Creates config and locates videos\n",
    "\n",
    "As always, make sure to read through the config parameters before running.elpers.get_video_data(config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>Set ROI</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Manually specify your roi\n",
    "\n",
    "This is good if your animal doesn't fill the view and if you have stationary objects nearby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.util import set_roi\n",
    "\n",
    "### Select POLYGON SUBFRAME for DISPLACEMENT Eignfaces\n",
    "## This block of code will pop up a little GUI. Click around the\n",
    "## region of the face that you want to include in the analysis.\n",
    "## When you are done, press enter twice to accept and exit the GUI.\n",
    "\n",
    "config = helpers.load_config(config_filepath)\n",
    "config['vidToSet'] = 1 # 1 indexed. Sets the video to use to make an image\n",
    "config['frameToSet'] = 2 # 1 indexed. Sets the frame number to use to make an image\n",
    "config['save_dir'] = str(Path('../data/processed').resolve())\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "pts_all = set_roi.roi_workflow(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = helpers.load_config(config_filepath)\n",
    "save_name = f'pts_all'\n",
    "save_fullPath = f'{config['save_dir']}/{save_name}.npy'\n",
    "np.save(save_fullPath , pts_all)\n",
    "config['path_pts_all'] = save_fullPath\n",
    "helpers.save_config(config, config_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Run Optic Flow</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Run as either mono or multi threaded depending on run time and number of dots\n",
    "\n",
    "Multithread may struggle when too many dots are selected (memory overload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.optic_flow import optic_flow\n",
    "\n",
    "### IMPORT and CALCULATE DISPLACEMENT FIELD\n",
    "### __SINGLE(ish) THREAD__ VERSION\n",
    "\n",
    "### Calculate DISPLACEMENT FIELD using dot grid within subframe\n",
    "## The only thing coming out of the code block that matters is the 'displacements' variable\n",
    "\n",
    "## I use imageio (ffmpeg) because openCV doesn't seem to import as many frames as imageio does (wtfffff), \n",
    "## and I can't preallocate because openCV and imageio give inaccurate total frame numbers from metadata (WTFFFF).\n",
    "\n",
    "## Important assumptions about using this code verses the single (ish) threaded version:\n",
    "## 1. numFrames (per file) + 1000 (USING OPENCVs cv2.CAP_PROP_FRAME_COUNT) must be > true number of frames\n",
    "##  as found using the imageio import method\n",
    "## 2. Debugging is hard. If you interrupt the kernel while it's doing the parallel pool, the kernel is kind of fucked\n",
    "##  and generally requires a restart\n",
    "## 3. I haven't figured out how to track progress. I know there are probably ways to make wait bars, but I'll leave that\n",
    "##  to a software engineer.\n",
    "\n",
    "### == PREFERENCES ==\n",
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "config['vidNums_toUse'] = range(config['numVids']) ## 0 indexing\n",
    "config['spacing'] = 3  ## This is the distance between points in the grid (both in x and y dims)\n",
    "\n",
    "config['showVideo_pref'] = False  ## much faster when video is off\n",
    "config['dot_size'] = 1  ## for viewing purposes\n",
    "\n",
    "## below will print the fps ever 'fps_counterPeriod' . Useful for checking the speed of import.\n",
    "## Best to turn off when doing a full run. (this is mostly for optimizing and debugging)\n",
    "config['printFPS_pref'] = False\n",
    "config['fps_counterPeriod'] = 10 ## number of frames to do a tic toc over\n",
    "\n",
    "## Parameters for lucas kanade optical flow\n",
    "## win size: spatial integration window (make small as possible, but make bigger if youre having issues with outliers)\n",
    "## max level: only moderate effects if everything working properly. Keep around 3.\n",
    "## criteria values have to do with the search algorithm. For speed: EPS small, COUNT big.\n",
    "config['lk_winSize']  = (35,35)\n",
    "config['lk_maxLevel'] = 4\n",
    "config['lk_criteria']    = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 100, 0.001)\n",
    "\n",
    "config['optic_multithread'] = True\n",
    "\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "\n",
    "### == CALCULATION ==\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "displacements, pointInds_toUse = optic_flow.optic_workflow(config_filepath)\n",
    "\n",
    "toc = time.time() - tic\n",
    "\n",
    "    \n",
    "print(f'\\n ===== Displacement calculation completed! =====')\n",
    "print(f'Total elapsed time: {round(toc/(60*60) , 2)} hours')\n",
    "print(f'Average frames per second: {round(numFrames_total/toc , 2)} fps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## This cell block is here just because sometimes its nice to cancel early out of the iterative loading (above cell block) and just play with a short trace. This block cleans out the NaNs\n",
    "displacements = displacements[:,:,~np.isnan(displacements[0,0,:])]  # this removes the trailing and interleaved NaNs in the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "save_dir = config['save_dir']\n",
    "\n",
    "save_name = f'pointInds_toUse'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , pointInds_toUse)\n",
    "config['path_pointsInds_toUse'] = save_fullPath\n",
    "\n",
    "save_name = f'displacements'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , displacements)\n",
    "config['path_displacements'] = save_fullPath\n",
    "\n",
    "helpers.save_config(config, config_filepath)\n",
    "\n",
    "# save_name = f'params_video'\n",
    "# save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "# np.save(save_fullPath , params_video)\n",
    "\n",
    "# save_name = f'Fs'\n",
    "# save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "# np.save(save_fullPath , Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "\n",
    "displacements = np.load(config['path_displacements'])\n",
    "pointInds_toUse = np.load(config['path_pointsInds_toUse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "<center><h1>Clean Optic Flow</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Clean up displacements traces and make good positions traces\n",
    "\n",
    "Check the parameters here, they are essential for getting good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from face_rhythm.optic_flow import clean_results\n",
    "\n",
    "## Create position trace from displacements\n",
    "## This block does a few things:\n",
    "\n",
    "## 1. Finds outliers: These are currently defined as time points when the integrated position goes beyond some threshold.\n",
    "##  Note that since displacements are calculated for x and y separately, outlier events are also separated into x outlier events\n",
    "##  and y outlier events.\n",
    "\n",
    "## 2. Sets displacements during outlier events to ZERO: There are some parameters below that define the time window (in frames)\n",
    "##  before and after outliers to also set to zero. Note again, that DISPLACEMENT (the derivative of position) is set to zero, \n",
    "##  effectively pausing the position of the ingegrated position.\n",
    "\n",
    "## 3. Rectifies the position to its 'anchor position': I am defining position as the integrated displacement arising from a STATIC\n",
    "##  place in the image. Because this analysis is image agnostic, drift naturally occurs. This term counteracts drift by simply\n",
    "##  relaxing each dot's position back to the center of its displacement analysis window. This term should be as low as possible\n",
    "##  because it also acts as a high pass filter, thus precluding analysis of slow timescale changes.\n",
    "\n",
    "## Note that using a standard frequency filter (fir, iir) here for the rectification / relaxation doesn't work well\n",
    "\n",
    "positions_new_sansOutliers = clean_results.clean_workflow(displacements)\n",
    "\n",
    "## Make a positions trace where each point centers around it's coordinates instead of zero (used for plotting)\n",
    "tic = time.time()\n",
    "positions_new_absolute_sansOutliers = positions_new_sansOutliers + np.squeeze(pointInds_toUse)[:,:,None]\n",
    "print(f'Made an absolute integrated position. Elapsed time: {round(time.time() - tic , 1)} seconds')\n",
    "\n",
    "toc_all = time.time() - tic_all\n",
    "print(f'total elapsed time: {round(toc_all/60,2)} minutes')\n",
    "print(f'== End outlier removal ==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = helpers.load_config(config_filepath)\n",
    "\n",
    "save_dir = config['save_dir']\n",
    "\n",
    "# save_name = f'positions_new_absolute_sansOutliers'\n",
    "# save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "# np.save(save_fullPath , positions_new_absolute_sansOutliers)\n",
    "\n",
    "save_name = f'positions_new_sansOutliers'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , positions_new_sansOutliers)\n",
    "config['path_positions'] = save_fullPath\n",
    "\n",
    "helpers.save_config(config, config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### The upcoming calculations make big data. It's best to delete everything we can from the memory. Consider restarting the kernel and importing just positions_new_sansOutliers\n",
    "del positions_tracked_outliers\n",
    "del positions_tracked_outliers_extended\n",
    "del displacements_simpleOutliersRemoved\n",
    "del displacements_sansOutliers\n",
    "del positions_new\n",
    "\n",
    "# del positions_new_absolute_sansOutliers\n",
    "\n",
    "del displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Take a quick look at one of the pixel's traces\n",
    "## Check for significant outliers\n",
    "%matplotlib notebook\n",
    "\n",
    "pixelNum_toUse = 300\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(positions_new_sansOutliers[pixelNum_toUse,0,:])\n",
    "# plt.figure()\n",
    "# plt.plot(displacements[pixelNum_toUse,0,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional dimensionality reduction\n",
    "The point here is to do some denoising and to get the number of dots down to a managable number.\\\n",
    "In particular, it is nice for the batched CP decomposition later that the batches can be as big as possible in the temporal dimension, so doing some mild convolutional dim reduction first is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## first let's make the convolutional kernel. I like the cosine kernel because it goes to zero.\n",
    "\n",
    "width_cosKernel = 40\n",
    "\n",
    "num_dots = pointInds_toUse.shape[0]\n",
    "\n",
    "def makeDistanceMatrix(n , centerIdx , vid_height , vid_width):\n",
    "    x,y = np.meshgrid(range(vid_width),range(vid_height)) # note dim 1:X and dim 2:Y\n",
    "    return np.sqrt((y-int(centerIdx[1]))**2+(x-int(centerIdx[0]))**2)\n",
    "\n",
    "cosKernel = np.zeros((vid_height , vid_width , num_dots))\n",
    "cosKernel_mean = np.zeros(num_dots)\n",
    "for ii in range(num_dots):\n",
    "    x = makeDistanceMatrix(width_cosKernel , np.squeeze(pointInds_toUse)[ii] , vid_height , vid_width)\n",
    "    x_norm = x / width_cosKernel\n",
    "    x_clipped = np.minimum(x_norm , 1)\n",
    "    cosKernel[:,:,ii] = (np.cos(x_clipped * np.pi) +1) / 2\n",
    "    tmp = copy.deepcopy(cosKernel[:,:,ii])\n",
    "    tmp[tmp==0] = np.nan\n",
    "    cosKernel_mean[ii] = np.nanmean(tmp)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cosKernel[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "\n",
    "save_name = f'cosKernel'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , cosKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## now the fun part: a bajillion dimensionality reductions\n",
    "\n",
    "# first, let's make new dots with wider spacing\n",
    "\n",
    "spacing = 8  ## This is the distance between points in the grid (both in x and y dims)\n",
    "\n",
    "pts_spaced_convDR = np.ones((np.int64(bbox_subframe_displacement[3] * bbox_subframe_displacement[2] / spacing) ,2)) * np.nan ## preallocation\n",
    "cc = 0 ## set idx counter\n",
    "# make spaced out points\n",
    "for ii in range(len(pts_x_displacement)):\n",
    "    if (pts_x_displacement[ii]%spacing == 0) and (pts_y_displacement[ii]%spacing == 0):\n",
    "        pts_spaced_convDR[cc,0] = pts_x_displacement[ii]\n",
    "        pts_spaced_convDR[cc,1] = pts_y_displacement[ii]\n",
    "        cc = cc+1\n",
    "\n",
    "pts_spaced_convDR = np.expand_dims(pts_spaced_convDR,1).astype('single')\n",
    "pts_spaced_convDR = np.delete(pts_spaced_convDR , np.where(np.isnan(pts_spaced_convDR[:,0,0])) , axis=0)\n",
    "print(f'number of points: {pts_spaced_convDR.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now let's show the dots we just made\n",
    "\n",
    "vidNum_toUse = 0 # 0 indexed\n",
    "frameNum_toUse = 0 # 0 indexed\n",
    "dot_size = 1\n",
    "\n",
    "## Define random colors for points in cloud\n",
    "color_tuples =  list(np.arange(len(pts_x_displacement)))\n",
    "for ii in range(len(pts_x_displacement)):\n",
    "    color_tuples[ii] = (np.random.rand(1)[0]*255, np.random.rand(1)[0]*255 , np.random.rand(1)[0]*255)\n",
    "    \n",
    "vid = imageio.get_reader(path_vid_allFiles[vidNum_toUse],  'ffmpeg')\n",
    "frameToSet = 0\n",
    "frame = vid.get_data(frameNum_toUse) # Get a single frame to use as the first 'previous frame' in calculating optic flow\n",
    "pointInds_tuple = list(np.arange(pts_spaced_convDR.shape[0])) \n",
    "for ii in range(pts_spaced_convDR.shape[0]):\n",
    "    pointInds_tuple[ii] = tuple(np.squeeze(pts_spaced_convDR[ii,0,:]))\n",
    "    cv2.circle(frame,pointInds_tuple[ii], dot_size, color_tuples[ii], -1)\n",
    "cv2.imshow('dots for conv dim red',frame)\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## now let's find coefficients of influence from each original dot onto each new dot\n",
    "\n",
    "input_traces = np.float32(positions_new_sansOutliers)\n",
    "num_components = 2\n",
    "rank_reduced = num_components\n",
    "\n",
    "dots_old = pointInds_toUse\n",
    "dots_new = pts_spaced_convDR\n",
    "\n",
    "pca = sk.decomposition.PCA(n_components=num_components)\n",
    "\n",
    "positions_convDR_meanSub = np.zeros((dots_new.shape[0] , 2 , input_traces.shape[2]))\n",
    "output_PCA_loadings = np.zeros((dots_new.shape[0] , 2 , input_traces.shape[2] , num_components))\n",
    "output_PCA_scores = list(np.zeros(dots_new.shape[0]))\n",
    "for ii in range(dots_new.shape[0]):\n",
    "#     print(ii)\n",
    "    influence_weightings = cosKernel[int(dots_new[ii][0][1]) , int(dots_new[ii][0][0]) , :]\n",
    "    \n",
    "    idx_nonZero = np.array(np.where(influence_weightings !=0))[0,:]\n",
    "\n",
    "    displacements_preConvDR_x = input_traces[idx_nonZero , 0 , :] * influence_weightings[idx_nonZero][:,None]\n",
    "    displacements_preConvDR_x = displacements_preConvDR_x - np.mean(displacements_preConvDR_x , axis=1)[:,None]\n",
    "    displacements_preConvDR_y = input_traces[idx_nonZero , 1 , :] * influence_weightings[idx_nonZero][:,None]\n",
    "    displacements_preConvDR_y = displacements_preConvDR_y - np.mean(displacements_preConvDR_y , axis=1)[:,None]\n",
    "    pca.fit(displacements_preConvDR_x)\n",
    "    output_PCA_loadings[ii,0,:,:] = pca.components_.T\n",
    "    pca.fit(displacements_preConvDR_y)\n",
    "    output_PCA_loadings[ii,1,:,:] = pca.components_.T\n",
    "    \n",
    "    output_PCA_scores[ii] = np.zeros((2,displacements_preConvDR_y.shape[0] , num_components))\n",
    "    output_PCA_scores[ii][0,:,:] = np.dot( displacements_preConvDR_x  ,  output_PCA_loadings[ii,0,:,:] )\n",
    "    output_PCA_scores[ii][1,:,:] = np.dot( displacements_preConvDR_y  ,  output_PCA_loadings[ii,1,:,:] )\n",
    "    positions_convDR_meanSub[ii,0,:] = np.mean(np.dot( output_PCA_loadings[ii,0,:,:rank_reduced] , output_PCA_scores[ii][0,:,:rank_reduced].T ) , axis=1) / cosKernel_mean[ii]\n",
    "    positions_convDR_meanSub[ii,1,:] = np.mean(np.dot( output_PCA_loadings[ii,1,:,:rank_reduced] , output_PCA_scores[ii][1,:,:rank_reduced].T ) , axis=1) / cosKernel_mean[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## now let's find coefficients of influence from each original dot onto each new dot\n",
    "# CAUTION: Huge memory requirement (Lower number of CPUs in the pool to decrease memory usage. For my runs (1 hr at 120hz, downsampling to ~400 dots, I use 18 cores and it\n",
    "# uses around 150GB of memory. Use single thread version otherwise)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "input_traces = np.float32(positions_new_sansOutliers)\n",
    "num_components = 2\n",
    "rank_reduced = num_components\n",
    "\n",
    "dots_old = pointInds_toUse\n",
    "dots_new = pts_spaced_convDR\n",
    "\n",
    "pca = sk.decomposition.PCA(n_components=num_components)\n",
    "\n",
    "\n",
    "def makeConvDR(ii):\n",
    "#     print(ii)\n",
    "    influence_weightings = cosKernel[int(dots_new[ii][0][1]) , int(dots_new[ii][0][0]) , :]\n",
    "    \n",
    "    idx_nonZero = np.array(np.where(influence_weightings !=0))[0,:]\n",
    "\n",
    "    displacements_preConvDR_x = input_traces[idx_nonZero , 0 , :] * influence_weightings[idx_nonZero][:,None]\n",
    "    displacements_preConvDR_x = displacements_preConvDR_x - np.mean(displacements_preConvDR_x , axis=1)[:,None]\n",
    "    displacements_preConvDR_y = input_traces[idx_nonZero , 1 , :] * influence_weightings[idx_nonZero][:,None]\n",
    "    displacements_preConvDR_y = displacements_preConvDR_y - np.mean(displacements_preConvDR_y , axis=1)[:,None]\n",
    "    pca.fit(displacements_preConvDR_x)\n",
    "    output_PCA_loadings0 = pca.components_.T\n",
    "    pca.fit(displacements_preConvDR_y)\n",
    "    output_PCA_loadings1 = pca.components_.T\n",
    "    \n",
    "    output_PCA_scores0 = np.dot( displacements_preConvDR_x  ,  output_PCA_loadings0 )\n",
    "    output_PCA_scores1 = np.dot( displacements_preConvDR_y  ,  output_PCA_loadings1 )\n",
    "    positions_convDR_meanSub = np.zeros((2,input_traces.shape[2]))\n",
    "    positions_convDR_meanSub[0,:] = np.mean(np.dot( output_PCA_loadings0[:,:rank_reduced] , output_PCA_scores0[:,:rank_reduced].T ) , axis=1) / cosKernel_mean[ii]\n",
    "    positions_convDR_meanSub[1,:] = np.mean(np.dot( output_PCA_loadings1[:,:rank_reduced] , output_PCA_scores1[:,:rank_reduced].T ) , axis=1) / cosKernel_mean[ii]\n",
    "    return positions_convDR_meanSub\n",
    "\n",
    "# p = Pool(multiprocessing.cpu_count())\n",
    "p = Pool(int(multiprocessing.cpu_count()/3))\n",
    "positions_convDR_meanSub_list = p.map(makeConvDR , range(dots_new.shape[0]))\n",
    "p.close()\n",
    "p.terminate()\n",
    "p.join()\n",
    "\n",
    "positions_convDR_meanSub = np.zeros((dots_new.shape[0] , 2 , input_traces.shape[2]))\n",
    "for ii in range(dots_new.shape[0]):\n",
    "    positions_convDR_meanSub[ii,:,:] = positions_convDR_meanSub_list[ii]\n",
    "    \n",
    "print(f'Time elapsed: {round((time.time() - tic)/60,2)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p.close()\n",
    "p.terminate()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "\n",
    "save_name = f'positions_convDR_meanSub'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , positions_convDR_meanSub)\n",
    "\n",
    "save_name = f'pts_spaced_convDR'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , pts_spaced_convDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run6'\n",
    "\n",
    "load_name = f'positions_convDR_meanSub'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "positions_convDR_meanSub = np.load(load_fullPath)\n",
    "\n",
    "load_name = f'pts_spaced_convDR'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "pts_spaced_convDR = np.load(load_fullPath)\n",
    "\n",
    "\n",
    "positions_convDR_absolute = (positions_convDR_meanSub + np.squeeze(pts_spaced_convDR)[:,:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Display video of displacement dot-grid after outlier removal\n",
    "## Just for observation purposes\n",
    "\n",
    "# positions_toUse = positions_new_absolute_sansOutliers\n",
    "positions_toUse = (positions_convDR_meanSub + np.squeeze(pts_spaced_convDR)[:,:,None])\n",
    "\n",
    "# vidNums_toUse = range(numVids) ## note zero indexing!\n",
    "vidNums_toUse = range(3) ## note zero indexing!\n",
    "\n",
    "if type(vidNums_toUse) == int:\n",
    "    vidNums_toUse = np.array([vidNums_toUse])\n",
    "\n",
    "dot_size = 1\n",
    "\n",
    "printFPS_pref = 0\n",
    "fps_counterPeriod = 10 ## number of frames to do a tic toc over\n",
    "\n",
    "\n",
    "## Define random colors for points in cloud\n",
    "color_tuples =  list(np.arange(positions_toUse.shape[0]))\n",
    "for ii in range(positions_toUse.shape[0]):\n",
    "    color_tuples[ii] = (np.random.rand(1)[0]*255, np.random.rand(1)[0]*255 , np.random.rand(1)[0]*255)\n",
    "#     color_tuples[ii] = (0,255,255)\n",
    "        \n",
    "        \n",
    "\n",
    "## Main loop to pull out displacements in each video   \n",
    "ind_concat = int(np.hstack([0 , np.cumsum(numFrames_allFiles)])[vidNums_toUse[0]])\n",
    "\n",
    "fps = 0\n",
    "tic_fps = time.time()\n",
    "for iter_vid , vidNum_iter in enumerate(vidNums_toUse):\n",
    "    path_vid = path_vid_allFiles[vidNum_iter]\n",
    "    vid = imageio.get_reader(path_vid,  'ffmpeg')\n",
    "\n",
    "    video = cv2.VideoCapture(path_vid)\n",
    "    numFrames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for iter_frame , new_frame in enumerate(vid):\n",
    "        for ii in range(positions_toUse.shape[0]):\n",
    "            pointInds_tracked_tuple = tuple(np.int64(np.squeeze(positions_toUse[ii,:,ind_concat])))\n",
    "            cv2.circle(new_frame,pointInds_tracked_tuple, dot_size, color_tuples[ii], -1)\n",
    "        \n",
    "        cv2.putText(new_frame, f'frame #: {iter_frame}/{numFrames}-ish', org=(10,20), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "        cv2.putText(new_frame, f'vid #: {iter_vid+1}/{len(vidNums_toUse)}', org=(10,40), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "        cv2.putText(new_frame, f'total frame #: {ind_concat+1}/{numFrames_total_rough}-ish', org=(10,60), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "        cv2.putText(new_frame, f'fps: {np.uint32(fps)}', org=(10,80), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "        cv2.imshow('post outlier removal',new_frame)\n",
    "\n",
    "\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27 : break\n",
    "            \n",
    "        ind_concat = ind_concat+1\n",
    "\n",
    "        \n",
    "        if ind_concat%fps_counterPeriod==0:\n",
    "            elapsed = time.time() - tic_fps\n",
    "            fps = fps_counterPeriod/elapsed\n",
    "            if printFPS_pref:\n",
    "                print(fps)\n",
    "            tic_fps = time.time()\n",
    "            \n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center><h1>Analysis</h1></center>\n",
    "\n",
    "***\n",
    "\n",
    "### Decompose and Analyze the Data in different ways\n",
    "\n",
    "Below you'll find the following:\n",
    "- PCA done on raw positions\n",
    "- Spectral analysis of every pixels to transoform the basis to be oscillatory\n",
    "- TCA done on the spectra\n",
    "- A lonely t-SNE plot of the temporal factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "The X and Y displacements are concatenated and run together. Something interesting to try would be to transform to polar coordinates, concatenate and run that way. Maybe TCA on the positions with magnitude vs angle being one of the dimensions would make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# input_dimRed = np.squeeze(positions_new_sansOutliers[:,1,:])\n",
    "tmp_x = np.squeeze(positions_convDR_meanSub[:,0,:])\n",
    "tmp_y = np.squeeze(positions_convDR_meanSub[:,1,:])\n",
    "                   \n",
    "input_dimRed_meanSub = np.concatenate((tmp_x - tmp_x.mean(1)[:,None] , tmp_y - tmp_y.mean(1)[:,None]) , axis=1 )\n",
    "# input_dimRed_concat = np.concatenate( (np.squeeze(positions_new_sansOutliers[:,0,:]) , np.squeeze(positions_new_sansOutliers[:,1,:])) , axis=1)\n",
    "\n",
    "# input_dimRed_meanSub = input_dimRed_concat - np.matlib.repmat( np.expand_dims(np.mean(input_dimRed_concat , axis=1) , axis=1) , 1 , input_dimRed_concat.shape[1])\n",
    "# input_dimRed_meanSub = input_dimRed_concat - input_dimRed_concat.mean(1)[:,None]\n",
    "\n",
    "pca = sk.decomposition.PCA(n_components=10)\n",
    "# pca = sk.decomposition.FastICA(n_components=10)\n",
    "pca.fit(np.float32(input_dimRed_meanSub))\n",
    "output_PCA = pca.components_.transpose()\n",
    "scores_points = np.dot(input_dimRed_meanSub , output_PCA)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(positions_tracked[:,])\n",
    "plt.figure()\n",
    "plt.plot(output_PCA[:,:3])\n",
    "plt.figure()\n",
    "plt.plot(pca.explained_variance_)\n",
    "plt.figure()\n",
    "plt.plot(output_PCA[:,0] , output_PCA[:,1]  , linewidth=.1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(scores_points[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# del input_dimRed_concat\n",
    "del input_dimRed_meanSub\n",
    "del tmp_x\n",
    "del tmp_y\n",
    "del output_PCA\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Prepare Tensorly\n",
    "\n",
    "pref_useGPU = 0\n",
    "\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "# If the input is small ( < half the size of your GPU memory) and you have CUDA, set to 'gpu'. It's super fast.\n",
    "if pref_useGPU:\n",
    "    cuda_device_number = torch.cuda.current_device()\n",
    "    print(f\"using CUDA device: 'cuda:{cuda_device_number}'\")\n",
    "    device = f'cuda:{cuda_device_number}'\n",
    "else:\n",
    "    print(f\"using CPU\")\n",
    "    device = 'cpu'  \n",
    "\n",
    "\n",
    "## Prepare the input tensor\n",
    "print(f'== Starting loading tensor ==')\n",
    "tic = time.time()\n",
    "\n",
    "input_tensor = tl.tensor(positions_convDR_meanSub, dtype=tl.float32, device=device, requires_grad=False)\n",
    "print(f'== Finished loading tensor. Elapsed time: {round(time.time() - tic,2)} seconds ==')\n",
    "\n",
    "print(f'Size of input (spectrogram): {input_tensor.shape}')\n",
    "\n",
    "print(f'{round(sys.getsizeof(input_dimRed_meanSub)/1000000000,3)} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Fit TCA model\n",
    "## If the input is small, set init='svd'\n",
    "\n",
    "rank = 4\n",
    "\n",
    "weights, factors_positional = tensorly.decomposition.parafac(input_tensor, init='random', tol=1e-06, n_iter_max=800, rank=rank, verbose=True, orthogonalise=False, random_state=1234)\n",
    "# weights, factors = tensorly.decomposition.non_negative_parafac(Sxx_allPixels_tensor[:,:,:,:], init='svd', tol=1e-05, n_iter_max=100, rank=rank, verbose=True,)\n",
    "# weights, factors = tensorly.decomposition.parafac(Sxx_allPixels_tensor, init='random', tol=1e-05, n_iter_max=1000, rank=rank, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## make numpy version of tensorly output\n",
    "\n",
    "factors_toUse = factors_positional\n",
    "\n",
    "\n",
    "if pref_useGPU:\n",
    "    factors_np_positional = list(np.arange(len(factors_toUse)))\n",
    "    for ii in range(len(factors_toUse)):\n",
    "#         factors_np[ii] = tl.tensor(factors[ii] , dtype=tl.float32 , device='cpu')\n",
    "        factors_np_positional[ii] = factors_toUse[ii].cpu().clone().detach().numpy()\n",
    "else:\n",
    "    factors_np_positional = []\n",
    "    for ii in range(len(factors_toUse)):\n",
    "        factors_np_positional.append(np.array(factors_toUse[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(factors_np_positional)\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "factors_toUse = factors_np_positional\n",
    "modelRank = factors_toUse[0].shape[1]\n",
    "## just for plotting in case \n",
    "if 'Fs' not in globals():\n",
    "    Fs = 120\n",
    "\n",
    "plt.figure()\n",
    "# plt.plot(np.arange(factors_toUse.factors(4)[0][2].shape[0])/Fs , factors_toUse.factors(4)[0][2])\n",
    "factors_temporal = scipy.stats.zscore(factors_toUse[2][:,:] , axis=0)\n",
    "factors_temporal = factors_toUse[2][:,:]\n",
    "# factors_temporal = scipy.stats.zscore(factors_temporal_reconstructed , axis=0)\n",
    "# plt.plot(np.arange(factors_temporal.shape[0])/Fs, factors_temporal[:,:])\n",
    "plt.plot(np.arange(factors_temporal.shape[0])/Fs, factors_temporal[:,])\n",
    "# plt.plot(factors_temporal[:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(factors_toUse[1][:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('x vs. y')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(factors_toUse[0][:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('pixel number')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.single(np.corrcoef(factors_toUse[2][:,:].T)))\n",
    "\n",
    "# input_dimRed = factors_toUse[2][:,:]\n",
    "# # input_dimRed_meanSub = \n",
    "# pca = sk.decomposition.PCA(n_components=modelRank-2)\n",
    "# # pca = sk.decomposition.FactorAnalysis(n_components=3)\n",
    "# pca.fit(np.single(input_dimRed).transpose())\n",
    "# output_PCA = pca.components_.transpose()\n",
    "# # scores_points = np.dot(ensemble.factors(4)[0][2] , output_PCA)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(output_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display video of factors\n",
    "\n",
    "factors_toShow = np.arange(factors_np_positional[0].shape[1])  # zero-indexed\n",
    "# factors_toShow = [3]  # zero-indexed\n",
    "\n",
    "for factor_iter in factors_toShow:\n",
    "\n",
    "    # vidNums_toUse = range(numVids) ## note zero indexing!\n",
    "    vidNums_toUse = 0 ## note zero indexing!\n",
    "\n",
    "    if type(vidNums_toUse) == int:\n",
    "        vidNums_toUse = np.array([vidNums_toUse])\n",
    "\n",
    "    dot_size = 2\n",
    "\n",
    "    printFPS_pref = 0\n",
    "    fps_counterPeriod = 10 ## number of frames to do a tic toc over\n",
    "\n",
    "#     modelRank_toUse = 5\n",
    "    factor_toShow = factor_iter+1\n",
    "    save_pref= 0\n",
    "\n",
    "    # save_dir = \"F:\\\\RH_Local\\\\Rich data\\\\camera data\"\n",
    "    save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "    save_fileName = f'factor {factor_toShow}'\n",
    "    # save_pathFull = f'{save_dir}\\\\{save_fileName}.avi'\n",
    "    save_pathFull = f'{save_dir}/{save_fileName}.avi'\n",
    "\n",
    "    # ensemble_toUse = ensemble\n",
    "    ensemble_toUse = factors_np_positional\n",
    "    positions_toUse = positions_convDR_absolute\n",
    "\n",
    "    factor_toShow = factor_toShow-1\n",
    "    # input_scores = ensemble_toUse.factors(modelRank_toUse)[0][0]\n",
    "    input_scores = np.single(ensemble_toUse[0])\n",
    "\n",
    "    range_toUse = np.ceil(np.max(input_scores[:,factor_toShow]) - np.min(input_scores[:,factor_toShow])) + 1\n",
    "    offset_toUse = np.min(input_scores[:,factor_toShow])\n",
    "    scores_norm = input_scores[:,factor_toShow] - offset_toUse\n",
    "    scores_norm = (scores_norm / np.max(scores_norm)) *1000\n",
    "    cmap = matplotlib.cm.get_cmap('hot', 1000)\n",
    "    # cmap_viridis(np.arange(range_toUse))\n",
    "\n",
    "    colormap_tuples =  list(np.arange(positions_toUse.shape[0]))\n",
    "    for ii in range(positions_toUse.shape[0]):\n",
    "        colormap_tuples[ii] = list(np.flip((np.array(cmap(np.int64(scores_norm[ii]))) *255)[:3]))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    if save_pref:\n",
    "        print(f'saving to file {save_pathFull}')\n",
    "        out = cv2.VideoWriter(save_pathFull, fourcc, Fs, (np.int64(vid_width), np.int64(vid_height)))\n",
    "\n",
    "\n",
    "    ## Main loop to pull out displacements in each video   \n",
    "    ind_concat = int(np.hstack([0 , np.cumsum(numFrames_allFiles)])[vidNums_toUse[0]])\n",
    "\n",
    "    fps = 0\n",
    "    tic_fps = time.time()\n",
    "    for iter_vid , vidNum_iter in enumerate(vidNums_toUse):\n",
    "        path_vid = path_vid_allFiles[vidNum_iter]\n",
    "        vid = imageio.get_reader(path_vid,  'ffmpeg')\n",
    "\n",
    "#         numFrames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        numFrames = 1000\n",
    "\n",
    "#         frameToSet = 0\n",
    "#         video.set(1,frameToSet)\n",
    "\n",
    "        for iter_frame , new_frame in enumerate(vid):\n",
    "\n",
    "#             ind_currentVid = np.int64(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            if iter_frame >= numFrames:\n",
    "                break\n",
    "#             ok, new_frame = video.read()\n",
    "\n",
    "            for ii in range(positions_toUse.shape[0]):\n",
    "                pointInds_tracked_tuple = tuple(np.int64(np.squeeze(positions_toUse[ii,:,ind_concat])))\n",
    "                cv2.circle(new_frame,pointInds_tracked_tuple, dot_size, colormap_tuples[ii], -1)\n",
    "            if save_pref:\n",
    "                out.write(new_frame)\n",
    "\n",
    "#             Sxx_frameNum = round( ind_currentVid / (positions_toUse.shape[2] / Sxx_allPixels.shape[2]) ,1)\n",
    "            cv2.putText(new_frame, f'frame #: {iter_frame}/{numFrames}', org=(10,20), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "#             cv2.putText(new_frame, f'frame #: {Sxx_frameNum}', org=(10,20), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "#             cv2.putText(new_frame, f'vid #: {iter+1}/{len(vidNums_toUse)}', org=(10,40), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.putText(new_frame, f'total frame #: {ind_concat+1}/{positions_toUse.shape[2]}', org=(10,60), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.putText(new_frame, f'fps: {np.uint32(fps)}', org=(10,80), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.putText(new_frame, f'factor num: {factor_iter+1} / {np.max(factors_toShow)+1}', org=(10,100), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.imshow('test',new_frame)\n",
    "\n",
    "\n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27 : break\n",
    "\n",
    "            ind_concat = ind_concat+1\n",
    "\n",
    "\n",
    "            if ind_concat%fps_counterPeriod==0:\n",
    "                elapsed = time.time() - tic_fps\n",
    "                fps = fps_counterPeriod/elapsed\n",
    "                if printFPS_pref:\n",
    "                    print(fps)\n",
    "                tic_fps = time.time()\n",
    "\n",
    "\n",
    "out.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display Factors\n",
    "\n",
    "positions_toUse = positions_convDR_absolute\n",
    "\n",
    "# vidNums_toUse = range(numVids) ## note zero indexing!\n",
    "vidNums_toUse = 0 ## note zero indexing!\n",
    "\n",
    "if type(vidNums_toUse) == int:\n",
    "    vidNums_toUse = np.array([vidNums_toUse])\n",
    "\n",
    "dot_size = 2\n",
    "\n",
    "printFPS_pref = 0\n",
    "fps_counterPeriod = 10 ## number of frames to do a tic toc over\n",
    "\n",
    "PC_toShow = 3\n",
    "PC_toShow = PC_toShow-1\n",
    "\n",
    "range_toUse = np.ceil(np.max(scores_points[:,PC_toShow]) - np.min(scores_points[:,PC_toShow])) + 1\n",
    "offset_toUse = np.min(scores_points[:,PC_toShow])\n",
    "scores_norm = scores_points[:,PC_toShow] - offset_toUse\n",
    "scores_norm = (scores_norm / np.max(scores_norm)) *1000\n",
    "cmap = matplotlib.cm.get_cmap('hot', 1000)\n",
    "\n",
    "\n",
    "colormap_tuples =  list(np.arange(pts_spaced_convDR.shape[0]))\n",
    "for ii in range(pts_spaced_convDR.shape[0]):\n",
    "    colormap_tuples[ii] = list(np.flip((np.array(cmap(np.int64(scores_norm[ii]))) *255)[:3]))\n",
    "        \n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "save_pref = 0\n",
    "if save_pref:\n",
    "    out = cv2.VideoWriter('F:\\RH_Local\\Rich data\\camera data\\output.avi',fourcc, Fs, (vid_width, vid_height))\n",
    "      \n",
    "\n",
    "## Main loop to pull out displacements in each video   \n",
    "ind_concat = int(np.hstack([0 , np.cumsum(numFrames_allFiles)])[vidNums_toUse[0]])\n",
    "\n",
    "fps = 0\n",
    "tic_fps = time.time()\n",
    "for iter_vid , vidNum_iter in enumerate(vidNums_toUse):\n",
    "    path_vid = path_vid_allFiles[vidNum_iter]\n",
    "    vid = imageio.get_reader(path_vid,  'ffmpeg')\n",
    "        \n",
    "    numFrames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for iter_frame , new_frame in enumerate(vid):\n",
    "        \n",
    "        for ii in range(positions_toUse.shape[0]):\n",
    "            pointInds_tracked_tuple = tuple(np.int64(np.squeeze(positions_toUse[ii,:,ind_concat])))\n",
    "            cv2.circle(new_frame,pointInds_tracked_tuple, dot_size, colormap_tuples[ii], -1)\n",
    "        if save_pref:\n",
    "            out.write(new_frame)\n",
    "            \n",
    "        cv2.putText(new_frame, f'frame #: {iter_frame}/{numFrames}', org=(10,20), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "        cv2.putText(new_frame, f'vid #: {iter_vid+1}/{len(vidNums_toUse)}', org=(10,40), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "#         cv2.putText(new_frame, f'total frame #: {ind_concat+1}/{numFrames_total}', org=(10,60), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "        cv2.putText(new_frame, f'fps: {np.uint32(fps)}', org=(10,80), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "        cv2.putText(new_frame, f'PC #: {PC_toShow+1}', org=(10,100), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "        cv2.imshow('PCs',new_frame)\n",
    "\n",
    "\n",
    "        k = cv2.waitKey(1) & 0xff\n",
    "        if k == 27 : break\n",
    "            \n",
    "        ind_concat = ind_concat+1\n",
    "\n",
    "        \n",
    "        if ind_concat%fps_counterPeriod==0:\n",
    "            elapsed = time.time() - tic_fps\n",
    "            fps = fps_counterPeriod/elapsed\n",
    "            if printFPS_pref:\n",
    "                print(fps)\n",
    "            tic_fps = time.time()\n",
    "            \n",
    "\n",
    "out.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Analysis\n",
    "I've played with a few different methods. While multiresolution methods seems ideal for this use-case, It just ends up severly overrepresenting low frequency factors, making noisier high frequency factors, and doing an overall worse job at reconstruction.\n",
    "A good ol' multitaper short time fourier transform seems to work fine. Adding in raw positions to subsequent dimensionality reduction later on seems like a natural thing to do, as single resolution spectral analysis ends up kind of ignoring slower dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run3'\n",
    "\n",
    "load_name = f'settings_cqt'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "settings_cqt = np.load(load_fullPath , allow_pickle=True)[()]\n",
    "\n",
    "\n",
    "hop_length = settings_cqt['hop_length']\n",
    "fmin = settings_cqt['fmin']\n",
    "sr = settings_cqt['sr']\n",
    "bins_per_octave = settings_cqt['bins_per_octave']\n",
    "n_bins = settings_cqt['n_bins']\n",
    "print(settings_cqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eps = 1.19209e-07 # float32 epsilon\n",
    "\n",
    "hop_length = 16\n",
    "fmin_rough = 2\n",
    "sr = Fs\n",
    "n_bins = 50\n",
    "\n",
    "bins_per_octave = int(np.round((n_bins) / np.log2( (Fs/2)/fmin_rough )))\n",
    "fmin = ( (Fs/2)/(2**((n_bins)/bins_per_octave)) ) - (2*eps)\n",
    "fmax = fmin*(2**((n_bins)/bins_per_octave))\n",
    "\n",
    "freqs_Sxx = fmin*(2**((np.arange(n_bins)+1)/bins_per_octave))\n",
    "\n",
    "print(f'bins_per_octave: {round(bins_per_octave)} bins/octave')\n",
    "print(f'minimum frequency (fmin): {round(fmin,3)} Hz')\n",
    "print(f'maximum frequency (fmax): {round(fmax,8)} Hz')\n",
    "print(f'Nyquist                 : {sr/2} Hz')\n",
    "print(f'number of frequencies:    {n_bins} bins')\n",
    "plt.figure()\n",
    "plt.plot(freqs_Sxx)\n",
    "print(f'Frequencies: {np.round(freqs_Sxx , 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Parameters for multitaper short-time Fourier transform\n",
    "\n",
    "settings_cqt =\t{\n",
    "    \"hop_length\": hop_length,  # number of samples between successive temporal samples\n",
    "    \"sr\": sr,  # sampling rate (Fs)\n",
    "    \"n_bins\": n_bins,  # Number of frequency bins, starting at fmin\n",
    "    \"bins_per_octave\": bins_per_octave,  #     Number of bins per octave\n",
    "    \"fmin\": fmin,  # Minimum frequency\n",
    "    \"fmax\": fmax,  # Maximum frequency (just for reference, not input to librosa.cqt)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "\n",
    "save_name = f'settings_cqt'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , settings_cqt)\n",
    "\n",
    "\n",
    "save_name = f'freqs_Sxx'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , freqs_Sxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### CQT spectrogram for every pixel\n",
    "## this code was previously parallelized, but it's pretty quick compared to the other steps, so might as well keep it simple\n",
    "\n",
    "print(f'== Starting CQT spectrogram calculations ==')\n",
    "tic_all = time.time()\n",
    "\n",
    "## define positions traces to use\n",
    "# input_sgram = np.single(np.squeeze(positions_new_sansOutliers))[:,:,:]\n",
    "input_sgram = np.single(np.squeeze(positions_convDR_meanSub))[:,:,:]\n",
    "\n",
    "## get parameters\n",
    "hop_length = hop_length\n",
    "fmin_rough = fmin_rough\n",
    "sr = sr\n",
    "n_bins = n_bins\n",
    "bins_per_octave = bins_per_octave\n",
    "fmin = fmin\n",
    "\n",
    "## make a single spectrogram to get some size parameters for preallocation\n",
    "Sxx = librosa.cqt(np.squeeze(input_sgram[0,0,:]), \n",
    "                  sr=sr, \n",
    "                  hop_length=hop_length, \n",
    "                  fmin=fmin, \n",
    "                  n_bins=n_bins, \n",
    "                  bins_per_octave=bins_per_octave, \n",
    "                  window='hann')\n",
    "\n",
    "# preallocation\n",
    "tic = time.time()\n",
    "print(f'preallocating')\n",
    "Sxx_allPixels = np.single(np.zeros((input_sgram.shape[0] , Sxx.shape[0] , Sxx.shape[1] , 2)))  \n",
    "print(f'preallocation done. Elapsed time: {round((time.time() - tic) , 2)} seconds')\n",
    "\n",
    "print(f'starting spectrogram calculation')\n",
    "for ii in range(input_sgram.shape[0]):\n",
    "    ## progress tracking\n",
    "    if ii%50 ==0:\n",
    "        print(f'{ii} / {Sxx_allPixels.shape[0]}')\n",
    "    elif ii==1:\n",
    "        print(f'{ii} / {Sxx_allPixels.shape[0]}')\n",
    "    \n",
    "    ## iterated over x and y\n",
    "    for jj in range(2):\n",
    "        tmp_input_sgram = np.squeeze(input_sgram[ii,jj,:])\n",
    "\n",
    "\n",
    "        tmp = librosa.cqt(np.squeeze(input_sgram[ii,jj,:]), \n",
    "                          sr=sr, \n",
    "                          hop_length=hop_length, \n",
    "                          fmin=fmin, \n",
    "                          n_bins=n_bins, \n",
    "                          bins_per_octave=bins_per_octave, \n",
    "                          window='hann')\n",
    "        \n",
    "        ## normalization\n",
    "        tmp = abs(tmp) * freqs_Sxx[:,None]\n",
    "#         tmp = scipy.stats.zscore(tmp , axis=0)\n",
    "#         tmp = test - np.min(tmp , axis=0)[None,:]\n",
    "#         tmp = scipy.stats.zscore(tmp , axis=1)\n",
    "#         tmp = tmp - np.min(tmp , axis=1)[:,None]\n",
    "\n",
    "        Sxx_allPixels[ii,:,:,jj] = tmp\n",
    "# Sxx_allPixels = Sxx_allPixels / np.std(Sxx_allPixels , axis=1)[:,None,:,:]\n",
    "\n",
    "print(f'completed spectrogram calculation')\n",
    "print('Info about Sxx_allPixels:\\n')\n",
    "print(f'Shape: {Sxx_allPixels.shape}')\n",
    "print(f'Number of elements: {Sxx_allPixels.shape[0]*Sxx_allPixels.shape[1]*Sxx_allPixels.shape[2]*Sxx_allPixels.shape[3]}')\n",
    "print(f'Data type: {Sxx_allPixels.dtype}')\n",
    "print(f'size of Sxx_allPixels: {round(sys.getsizeof(Sxx_allPixels)/1000000000,3)} GB')\n",
    "print(f'== Spectrograms computed. Total elapsed time: {round((time.time() - tic_all)/60 , 2)} minutes ==')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Normalize the spectrograms so that each time point has a similar cumulative spectral amplitude across all dots (basically, sum of power of all frequencies from all dots at a particular time should equal one)\n",
    "## hold onto the normFactor variable because you can use to it to undo the normalization after subsequent steps\n",
    "Sxx_allPixels_normFactor = np.mean(np.sum(Sxx_allPixels , axis=1) , axis=0)\n",
    "Sxx_allPixels_norm = Sxx_allPixels / Sxx_allPixels_normFactor[None,None,:,:]\n",
    "Sxx_allPixels_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(Sxx_allPixels_norm[500,:,:,0]  , aspect='auto' , cmap='hot' , origin='lower')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Sxx_allPixels_normFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Sxx_positional.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define positions traces to use\n",
    "input_sgram = np.single(np.squeeze(factors_np_positional[2][:,3]))\n",
    "\n",
    "## get parameters\n",
    "hop_length = 8\n",
    "fmin_rough = fmin_rough\n",
    "sr = sr\n",
    "n_bins = n_bins\n",
    "bins_per_octave = bins_per_octave\n",
    "fmin = fmin\n",
    "\n",
    "## make a single spectrogram to get some size parameters for preallocation\n",
    "Sxx_positional = librosa.cqt(np.squeeze(input_sgram), \n",
    "                            sr=sr, \n",
    "                            hop_length=hop_length, \n",
    "                            fmin=fmin, \n",
    "                            n_bins=n_bins, \n",
    "                            bins_per_octave=bins_per_octave, \n",
    "                            window=('hann'),\n",
    "                            filter_scale=0.8)\n",
    "Sxx_positional = abs(Sxx_positional) * freqs_Sxx[:,None]\n",
    "# Sxx_positional = abs(Sxx_positional)\n",
    "# test = scipy.stats.zscore(Sxx_positional , axis=0)\n",
    "test_std = np.std(Sxx_positional , axis=0)\n",
    "test_sum = np.sum(Sxx_positional , axis=0)\n",
    "test = Sxx_positional / (test_std[None,:] )\n",
    "# test = (Sxx_positional) / (test_sum[None,:])\n",
    "# test = test - np.min(test , axis=0)[None,:]\n",
    "\n",
    "test2 = scipy.stats.zscore(Sxx_positional , axis=1)\n",
    "test2 = test2 - np.min(test2 , axis=1)[:,None]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Sxx_positional , aspect='auto' , cmap='hot' , origin='lower')\n",
    "plt.figure()\n",
    "plt.imshow(test , aspect='auto' , cmap='hot' , origin='lower')\n",
    "plt.figure()\n",
    "plt.imshow(test2 , aspect='auto' , cmap='hot' , origin='lower')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading before TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "\n",
    "save_name = f'Sxx_allPixels'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , Sxx_allPixels)\n",
    "\n",
    "save_name = f'Sxx_allPixels_norm'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , Sxx_allPixels_norm)\n",
    "\n",
    "save_name = f'Sxx_allPixels_normFactor'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , Sxx_allPixels_normFactor)\n",
    "\n",
    "\n",
    "save_name = f'freqs_Sxx'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , freqs_Sxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run2'\n",
    "\n",
    "load_name = f'freqs_Sxx'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "freqs_Sxx = np.load(load_fullPath)\n",
    "\n",
    "load_name = f'Sxx_allPixels'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "Sxx_allPixels = np.load(load_fullPath)\n",
    "\n",
    "load_name = f'Fs'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "Fs = np.load(load_fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCA\n",
    "There are two major tensor packages, one is tensortools (made by an acquaintance named Alex Williams) and the other is Tensorly.\n",
    "Tensorly seems to be more packaged up and has some options to use some advanced backends like torch, tf, and mxnet. Though there are\n",
    "a couple of nice features in tensortools that Tensorly doesn't have, though. Generally tensortools gives better reconstructions, but takes\n",
    "much longer to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Prepare Tensorly\n",
    "\n",
    "pref_useGPU = 1\n",
    "\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "# If the input is small ( < half the size of your GPU memory) and you have CUDA, set to 'gpu'. It's super fast.\n",
    "if pref_useGPU:\n",
    "    cuda_device_number = torch.cuda.current_device()\n",
    "    print(f\"using CUDA device: 'cuda:{cuda_device_number}'\")\n",
    "    device = f'cuda:{cuda_device_number}'\n",
    "else:\n",
    "    print(f\"using CPU\")\n",
    "    device = 'cpu'  \n",
    "\n",
    "\n",
    "## Prepare the input tensor\n",
    "print(f'== Starting loading tensor ==')\n",
    "tic = time.time()\n",
    "Sxx_allPixels_tensor = tl.tensor(tmp[:,:,:,:], dtype=tl.float32, device=device, requires_grad=False)\n",
    "print(f'== Finished loading tensor. Elapsed time: {round(time.time() - tic,2)} seconds ==')\n",
    "\n",
    "print(f'Size of input (spectrogram): {Sxx_allPixels_tensor.shape}')\n",
    "\n",
    "print(f'{round(sys.getsizeof(Sxx_allPixels)/1000000000,3)} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del Sxx_allPixels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Fit TCA model\n",
    "## If the input is small, set init='svd'\n",
    "\n",
    "rank = 8\n",
    "\n",
    "weights, factors = tensorly.decomposition.non_negative_parafac(Sxx_allPixels_tensor[:,:,:,:], init='random', tol=1e-07, n_iter_max=400, rank=rank, verbose=True, orthogonalise=False, random_state=1234)\n",
    "# weights, factors = tensorly.decomposition.non_negative_parafac(Sxx_allPixels_tensor[:,:,:,:], init='svd', tol=1e-05, n_iter_max=100, rank=rank, verbose=True,)\n",
    "# weights, factors = tensorly.decomposition.parafac(Sxx_allPixels_tensor, init='random', tol=1e-05, n_iter_max=1000, rank=rank, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## make numpy version of tensorly output\n",
    "\n",
    "factors_toUse = factors\n",
    "\n",
    "\n",
    "if pref_useGPU:\n",
    "    factors_np = list(np.arange(len(factors)))\n",
    "    for ii in range(len(factors)):\n",
    "#         factors_np[ii] = tl.tensor(factors[ii] , dtype=tl.float32 , device='cpu')\n",
    "        factors_np[ii] = factors[ii].cpu().clone().detach().numpy()\n",
    "else:\n",
    "    factors_np = []\n",
    "    for ii in range(len(factors_toUse)):\n",
    "        factors_np.append(np.array(factors_toUse[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "\n",
    "save_name = f'factors_np'\n",
    "save_fullPath = f'{save_dir}/{save_name}.npy'\n",
    "np.save(save_fullPath , factors_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run6'\n",
    "\n",
    "load_name = f'factors_np_batchCPsqrt'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "factors_np = np.load(load_fullPath , allow_pickle=True)\n",
    "\n",
    "load_name = f'freqs_Sxx'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "\n",
    "freqs_Sxx = np.load(load_fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "factors_toUse = factors_np\n",
    "modelRank = factors_toUse[0].shape[1]\n",
    "## just for plotting in case \n",
    "if 'Fs' not in globals():\n",
    "    Fs = 120\n",
    "\n",
    "plt.figure()\n",
    "# plt.plot(np.arange(factors_toUse.factors(4)[0][2].shape[0])/Fs , factors_toUse.factors(4)[0][2])\n",
    "# factors_temporal = scipy.stats.zscore(factors_toUse[2][:,:] , axis=0)\n",
    "factors_temporal = factors_toUse[2][:,:]\n",
    "# factors_temporal = scipy.stats.zscore(factors_temporal_reconstructed , axis=0)\n",
    "# plt.plot(np.arange(factors_temporal.shape[0])/Fs, factors_temporal[:,:])\n",
    "plt.plot(np.arange(factors_temporal.shape[0])/Fs, factors_temporal[:,])\n",
    "# plt.plot(factors_temporal[:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "plt.figure()\n",
    "# plt.plot(np.arange(factors_toUse.factors(4)[0][2].shape[0])/Fs , factors_toUse.factors(4)[0][2])\n",
    "# factors_temporal = scipy.stats.zscore(factors_toUse[2][:,:] , axis=0)\n",
    "factors_temporal = factors_toUse[2][:,:] * (np.mean(Sxx_allPixels_normFactor , axis=1)[:,None] **(2/5))\n",
    "# factors_temporal = scipy.stats.zscore(factors_temporal_reconstructed , axis=0)\n",
    "# plt.plot(np.arange(factors_temporal.shape[0])/Fs, factors_temporal[:,:])\n",
    "plt.plot(np.arange(factors_temporal.shape[0])/Fs, factors_temporal[:,:])\n",
    "# plt.plot(factors_temporal[:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(freqs_Sxx , (factors_toUse[1][:,:]))\n",
    "# plt.plot(freqXaxis , (factors_toUse[1][:,:]))\n",
    "# plt.plot(f , (factors_toUse[1][:,:]))\n",
    "# plt.plot((factors_toUse[1][:,:]))\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('frequency (Hz)')\n",
    "plt.ylabel('a.u.')\n",
    "# plt.xscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(factors_toUse[3][:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('x vs. y')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(factors_toUse[0][:,:])\n",
    "plt.legend(np.arange(modelRank)+1)\n",
    "plt.xlabel('pixel number')\n",
    "plt.ylabel('a.u.')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.single(np.corrcoef(factors_toUse[2][:,:].T)))\n",
    "\n",
    "input_dimRed = factors_toUse[2][:,:]\n",
    "# input_dimRed_meanSub = \n",
    "pca = sk.decomposition.PCA(n_components=modelRank-2)\n",
    "# pca = sk.decomposition.FactorAnalysis(n_components=3)\n",
    "pca.fit(np.single(input_dimRed).transpose())\n",
    "output_PCA = pca.components_.transpose()\n",
    "# scores_points = np.dot(ensemble.factors(4)[0][2] , output_PCA)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(output_PCA[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Do some cross-correlations\n",
    "input_factors = factors_np\n",
    "factors_xcorr = np.zeros((input_factors[2].shape[0] , input_factors[2].shape[1] , input_factors[2].shape[1]))\n",
    "for ii in range(input_factors[2].shape[1]):\n",
    "    for jj in range(input_factors[2].shape[1]):\n",
    "        factors_xcorr[:,ii,jj] = scipy.signal.correlate(input_factors[2][:,ii] , input_factors[2][:,jj] , mode='same')\n",
    "    print(ii)\n",
    "\n",
    "\n",
    "for ii in range(factors_xcorr.shape[1]):\n",
    "    print(ii+1)\n",
    "    plt.figure()\n",
    "    plt.plot(np.squeeze(factors_xcorr[:,ii,:]))\n",
    "    plt.legend(np.arange(modelRank)+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "load_name = f'positions_convDR_meanSub'\n",
    "load_fullPath = f'{load_dir}/{load_name}.npy'\n",
    "\n",
    "positions_convDR_meanSub = np.load(load_fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positions_convDR_absolute = positions_convDR_meanSub + np.squeeze(pts_spaced_convDR)[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display video of factors\n",
    "\n",
    "factors_toShow = np.arange(factors_np[0].shape[1])  # zero-indexed\n",
    "# factors_toShow = [3]  # zero-indexed\n",
    "\n",
    "for factor_iter in factors_toShow:\n",
    "\n",
    "    # vidNums_toUse = range(numVids) ## note zero indexing!\n",
    "    vidNums_toUse = 0 ## note zero indexing!\n",
    "\n",
    "    if type(vidNums_toUse) == int:\n",
    "        vidNums_toUse = np.array([vidNums_toUse])\n",
    "\n",
    "    dot_size = 2\n",
    "\n",
    "    printFPS_pref = 0\n",
    "    fps_counterPeriod = 10 ## number of frames to do a tic toc over\n",
    "\n",
    "#     modelRank_toUse = 5\n",
    "    factor_toShow = factor_iter+1\n",
    "    save_pref= 0\n",
    "\n",
    "    # save_dir = \"F:\\\\RH_Local\\\\Rich data\\\\camera data\"\n",
    "    save_dir = f'/media/rich/bigSSD RH/res2p/Camera data/round 4 experiments/mouse 6.28/20201102/cam3/run7'\n",
    "    save_fileName = f'factor {factor_toShow}'\n",
    "    # save_pathFull = f'{save_dir}\\\\{save_fileName}.avi'\n",
    "    save_pathFull = f'{save_dir}/{save_fileName}.avi'\n",
    "\n",
    "    # ensemble_toUse = ensemble\n",
    "    ensemble_toUse = factors_np\n",
    "    positions_toUse = positions_convDR_absolute\n",
    "\n",
    "    factor_toShow = factor_toShow-1\n",
    "    # input_scores = ensemble_toUse.factors(modelRank_toUse)[0][0]\n",
    "    input_scores = np.single(ensemble_toUse[0])\n",
    "\n",
    "    range_toUse = np.ceil(np.max(input_scores[:,factor_toShow]) - np.min(input_scores[:,factor_toShow])) + 1\n",
    "    offset_toUse = np.min(input_scores[:,factor_toShow])\n",
    "    scores_norm = input_scores[:,factor_toShow] - offset_toUse\n",
    "    scores_norm = (scores_norm / np.max(scores_norm)) *1000\n",
    "    cmap = matplotlib.cm.get_cmap('hot', 1000)\n",
    "    # cmap_viridis(np.arange(range_toUse))\n",
    "\n",
    "    colormap_tuples =  list(np.arange(positions_toUse.shape[0]))\n",
    "    for ii in range(positions_toUse.shape[0]):\n",
    "        colormap_tuples[ii] = list(np.flip((np.array(cmap(np.int64(scores_norm[ii]))) *255)[:3]))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    if save_pref:\n",
    "        print(f'saving to file {save_pathFull}')\n",
    "        out = cv2.VideoWriter(save_pathFull, fourcc, Fs, (np.int64(vid_width), np.int64(vid_height)))\n",
    "\n",
    "\n",
    "    ## Main loop to pull out displacements in each video   \n",
    "    ind_concat = int(np.hstack([0 , np.cumsum(numFrames_allFiles)])[vidNums_toUse[0]])\n",
    "\n",
    "    fps = 0\n",
    "    tic_fps = time.time()\n",
    "    for iter_vid , vidNum_iter in enumerate(vidNums_toUse):\n",
    "        path_vid = path_vid_allFiles[vidNum_iter]\n",
    "        vid = imageio.get_reader(path_vid,  'ffmpeg')\n",
    "\n",
    "#         numFrames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        numFrames = 1000\n",
    "\n",
    "#         frameToSet = 0\n",
    "#         video.set(1,frameToSet)\n",
    "\n",
    "        for iter_frame , new_frame in enumerate(vid):\n",
    "\n",
    "#             ind_currentVid = np.int64(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            if iter_frame >= numFrames:\n",
    "                break\n",
    "#             ok, new_frame = video.read()\n",
    "\n",
    "            for ii in range(positions_toUse.shape[0]):\n",
    "                pointInds_tracked_tuple = tuple(np.int64(np.squeeze(positions_toUse[ii,:,ind_concat])))\n",
    "                cv2.circle(new_frame,pointInds_tracked_tuple, dot_size, colormap_tuples[ii], -1)\n",
    "            if save_pref:\n",
    "                out.write(new_frame)\n",
    "\n",
    "#             Sxx_frameNum = round( ind_currentVid / (positions_toUse.shape[2] / Sxx_allPixels.shape[2]) ,1)\n",
    "            cv2.putText(new_frame, f'frame #: {iter_frame}/{numFrames}', org=(10,20), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "#             cv2.putText(new_frame, f'frame #: {Sxx_frameNum}', org=(10,20), fontFace=1, fontScale=1, color=(255,255,255), thickness=2)\n",
    "#             cv2.putText(new_frame, f'vid #: {iter+1}/{len(vidNums_toUse)}', org=(10,40), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.putText(new_frame, f'total frame #: {ind_concat+1}/{positions_toUse.shape[2]}', org=(10,60), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.putText(new_frame, f'fps: {np.uint32(fps)}', org=(10,80), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.putText(new_frame, f'factor num: {factor_iter+1} / {np.max(factors_toShow)+1}', org=(10,100), fontFace=1, fontScale=1, color=(255,255,255), thickness=1)\n",
    "            cv2.imshow('test',new_frame)\n",
    "\n",
    "\n",
    "            k = cv2.waitKey(1) & 0xff\n",
    "            if k == 27 : break\n",
    "\n",
    "            ind_concat = ind_concat+1\n",
    "\n",
    "\n",
    "            if ind_concat%fps_counterPeriod==0:\n",
    "                elapsed = time.time() - tic_fps\n",
    "                fps = fps_counterPeriod/elapsed\n",
    "                if printFPS_pref:\n",
    "                    print(fps)\n",
    "                tic_fps = time.time()\n",
    "\n",
    "\n",
    "out.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection, neighbors)\n",
    "print(\"Computing t-SNE embedding\")\n",
    "tsne = manifold.TSNE(n_components=2, init='pca',\n",
    "                     random_state=0, perplexity=200)\n",
    "X_tsne = tsne.fit_transform(factors_temporal)\n",
    "print(\"Finished computing t-SNE embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "factor_toCMap = 8  # 1 indexed\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "# plt.plot(X_tsne[:,0] , X_tsne[:,1] , linewidth=0.05)\n",
    "# plt.scatter(X_tsne[:,0] , X_tsne[:,1], 'r.' , markersize=0.6)\n",
    "plt.scatter(X_tsne[:,0] , X_tsne[:,1] , s=1.5, c=factors_temporal[:,factor_toCMap-1] , cmap='jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# das it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face-rhythm] *",
   "language": "python",
   "name": "conda-env-face-rhythm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 957.188,
   "position": {
    "height": "40px",
    "left": "1725.67px",
    "right": "20px",
    "top": "124.914px",
    "width": "628.438px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}