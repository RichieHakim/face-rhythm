{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2fd0e4",
   "metadata": {},
   "source": [
    "# serverteeny\n",
    "(Sabatin's teeny server)\n",
    "\n",
    "This script runs a server for receiving and executing ssh code. It does the following:\\\n",
    "Receiving:\n",
    "\n",
    "1. On startup: It establishes an SFTP connection with O2 using input server credentials.\n",
    "    - For safety, this is best done by setting up an ssh-key. Roughly, in the terminal do:\n",
    "        - `ssh-keygen -t rsa`\n",
    "        - `ssh-copy-id username@o2.hms.harvard.edu`\n",
    "        - `ssh username@o2.hms.harvard.edu`\n",
    "2. It continuosly searches for a `.json` file with a specific filename (`filename_search`) in a specific directory (`dir_search`). Regular expressions are used to compare the filename. Ex: `run.json`\n",
    "    - The `.json` file should be a python dictionary with the following fields:\n",
    "        1. `'name': 'Rich'`     : use the same name every time for logging purposes\n",
    "        2. `'o2_acct': 'joz608'`     : which user account on o2 to use for sending the ssh commands\n",
    "        3. `'time_sent': time.ctime()`     : send the current time at sending for logging purposes\n",
    "        4. `'notes': 'Experiment 3, mouse 5, suite2p'`     : Anything you want to log\n",
    "        5. `'command': 'python3 /n/data1/hms/neurobio/sabatini/rich/analysis/faceRhythm/dispatcher.py'`     : string to send as a command to o2/slurm\n",
    "3. If a file is found, it is downloaded to a local directory, and then it loads it in as a python dictionary.\n",
    "4. It establishes an ssh connection with O2 using the username in the `o2_acct` field.\n",
    "    - Users/Friends can allow use of the O2 account by following the steps in 1. to store their credentials securely on the computer\n",
    "5. It sends the command in the `'command'` field\n",
    "6. It logs the contents of the json file in a `logger.csv` which is stored on O2. This is done by downloading, importing, then uploading again via SFTP.\n",
    "7. It sends an email to `serverteeny@gmail.com` using SendGrid\n",
    "8. It cleans up by deleting the `.json` file from remote and closing the SSH object from o2_acct.\n",
    "9. Go back to step 2\n",
    "\n",
    "- Note: All temporary files (downloaded `.json` and `.csv` files are kept in `dir_tempFiles_local`)\n",
    "- In the serverteeny directory there are two subdirectories: `subdirName_run` where `.json` run files are searched for and `subdirName_logger` where the `.csv` file is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10922759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ALWAYS RUN THIS CELL\n",
    "# widen jupyter notebook window\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d48877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_github = '/media/rich/Home_Linux_partition/github_repos/'\n",
    "import sys\n",
    "sys.path.append(dir_github)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from basic_neural_processing_modules import server, email_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f36a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d09ac",
   "metadata": {},
   "source": [
    "# helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38316c",
   "metadata": {},
   "source": [
    "# 0. Set settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6efdaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName_search = 'run.json'\n",
    "fileName_logger = 'logger.csv'\n",
    "\n",
    "subdirName_run = 'run'\n",
    "subdirName_logger = 'logger'\n",
    "\n",
    "dir_serverteeny_remote = '/n/data1/hms/neurobio/sabatini/serverteeny'\n",
    "dir_tempFiles_local = '/media/rich/bigSSD/tmp_data/serverteeny_tmpFiles'\n",
    "\n",
    "pref_sendEmail = True\n",
    "\n",
    "n_sec_to_wait_after_finding_runFile = 10\n",
    "\n",
    "\n",
    "dir_run_remote = str(Path(dir_serverteeny_remote) / subdirName_run)\n",
    "\n",
    "path_loggerCsv_remote = str(Path(dir_serverteeny_remote) / subdirName_logger / 'logger_serverteeny.csv')\n",
    "path_loggerCsv_local = str(Path(dir_tempFiles_local) / 'logger_serverteeny.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a3211",
   "metadata": {},
   "source": [
    "# 1. Establish SFTP+SSH connection with O2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b69eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: rh183\n"
     ]
    }
   ],
   "source": [
    "remote_host_transfer = \"transfer.rc.hms.harvard.edu\"\n",
    "remote_host_compute = \"o2.hms.harvard.edu\"\n",
    "username = input('Username: ')\n",
    "\n",
    "use_localSshKey = True\n",
    "\n",
    "pw = server.pw_encode(getpass.getpass(prompt='Password: ')) if use_localSshKey==False else None\n",
    "\n",
    "path_sshKey = '/home/rich/.ssh/id_rsa' if use_localSshKey else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f7d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize ssh_compute\n",
    "ssh_scraper = server.ssh_interface(\n",
    "    nbytes_toReceive=20000,\n",
    "    recv_timeout=1,\n",
    "    verbose=True,\n",
    ")\n",
    "ssh_scraper.o2_connect(\n",
    "    hostname=remote_host_compute,\n",
    "    username=username,\n",
    "    password=server.pw_decode(pw),\n",
    "    key_filename=path_sshKey,\n",
    "    look_for_keys=False,\n",
    "    passcode_method=1,\n",
    "    verbose=0,\n",
    "    skip_passcode=False,    \n",
    ")\n",
    "sftp = server.sftp_interface(ssh_client=ssh_scraper.client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371fbb75",
   "metadata": {},
   "source": [
    "Find or make the remote serverteeny directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511d92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_verbose_remote(directory, dir_name=''):\n",
    "    found_directory = sftp.isdir_remote(directory)\n",
    "    if found_directory:\n",
    "        print(f'found remote {dir_name} directory:  {directory}')\n",
    "    else:\n",
    "        print(f'making remote {dir_name} directory:  {directory}')\n",
    "        sftp.mkdir_safe(directory)\n",
    "\n",
    "def mkdir_verbose_local(directory, dir_name=''):\n",
    "    found_directory = Path(directory).is_dir()\n",
    "    if found_directory:\n",
    "        print(f'found local {dir_name} directory:  {directory}')\n",
    "    else:\n",
    "        print(f'making local {dir_name} directory:  {directory}')\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1a1c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found remote serverteeny directory:  /n/data1/hms/neurobio/sabatini/serverteeny\n",
      "found remote serverteeny run directory:  /n/data1/hms/neurobio/sabatini/serverteeny/run\n",
      "found remote serverteeny logger directory:  /n/data1/hms/neurobio/sabatini/serverteeny/logger\n",
      "found local serverteeny temp directory:  /media/rich/bigSSD/tmp_data/serverteeny_tmpFiles\n"
     ]
    }
   ],
   "source": [
    "mkdir_verbose_remote(dir_serverteeny_remote, 'serverteeny')\n",
    "mkdir_verbose_remote(dir_run_remote, 'serverteeny run')\n",
    "mkdir_verbose_remote(str(Path(path_loggerCsv_remote).parent), 'serverteeny logger')\n",
    "\n",
    "mkdir_verbose_local(dir_tempFiles_local, 'serverteeny temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e27125",
   "metadata": {},
   "source": [
    "# 2. Search for `.json` run file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e4b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_first_match_remote(\n",
    "    dir_remote,\n",
    "    fileName,\n",
    "    verbose=True,\n",
    "    n_sec_to_wait_after_finding_runFile=n_sec_to_wait_after_finding_runFile,\n",
    "):\n",
    "    \"\"\"\n",
    "    Searches for fileName in dir_remote.\n",
    "    RH 2022\n",
    "    \"\"\"\n",
    "\n",
    "    found=False\n",
    "\n",
    "    while found==False:\n",
    "        contents = np.array(sftp.sftp.listdir(dir_remote))\n",
    "        comparisons = np.array([re.search(fileName, c) is not None for c in contents])\n",
    "        if sum(comparisons) > 0:\n",
    "            path_match = str(Path(dir_remote) / contents[comparisons][0])  ## just take the first index in case there are multiple matches\n",
    "            print(f'found match:  {path_match}')\n",
    "            \n",
    "            print(f'pausing for {n_sec_to_wait_after_finding_runFile} seconds')\n",
    "            time.sleep(n_sec_to_wait_after_finding_runFile)\n",
    "            \n",
    "            return path_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f6043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found match:  /n/data1/hms/neurobio/sabatini/serverteeny/run/run.json\n",
      "pausing for 10\n"
     ]
    }
   ],
   "source": [
    "path_runFile_remote = search_for_first_match_remote(dir_run_remote, fileName_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26671955",
   "metadata": {},
   "source": [
    "# 3. Download `.json` run file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df727d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading .json run file from  /n/data1/hms/neurobio/sabatini/serverteeny/run/run.json  to  /media/rich/bigSSD/tmp_data/serverteeny_tmpFiles/run.json\n"
     ]
    }
   ],
   "source": [
    "path_runFile_local = str(Path(dir_tempFiles_local) / Path(path_runFile_remote).name)\n",
    "\n",
    "print(f'downloading .json run file from  {path_runFile_remote}  to  {path_runFile_local}')\n",
    "sftp.sftp.get(\n",
    "    remotepath=path_runFile_remote,\n",
    "    localpath=path_runFile_local,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c411b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_runFile_local, mode='r') as f:\n",
    "    runFile = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4cedc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runFile = {\n",
    "#     'name': 'Rich',\n",
    "#     'o2_acct': 'rh183',\n",
    "#     'command': 'python3 /n/data1/hms/neurobio/sabatini/rich/analysis/faceRhythm/dispatcher.py',\n",
    "#     'notes': 'Experiment 3, mouse 5, suite2p',\n",
    "#     'time_sent': time.ctime(),\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d18f88b",
   "metadata": {},
   "source": [
    "# 4. Log into `o2_acct` using saved O2 account credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bf03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ssh_interface.__del__ at 0x7f45f95631f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/rich/Home_Linux_partition/github_repos/basic_neural_processing_modules/server.py\", line 395, in __del__\n",
      "    self.ssh.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n"
     ]
    }
   ],
   "source": [
    "## initialize ssh_compute\n",
    "ssh_c = server.ssh_interface(\n",
    "    nbytes_toReceive=20000,\n",
    "    recv_timeout=1,\n",
    "    verbose=True,\n",
    ")\n",
    "ssh_c.o2_connect(\n",
    "    hostname=remote_host_compute,\n",
    "    username=runFile['o2_acct'],\n",
    "    password=None,\n",
    "    key_filename=path_sshKey,\n",
    "    look_for_keys=False,\n",
    "    passcode_method=1,\n",
    "    verbose=0,\n",
    "    skip_passcode=False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b07c3",
   "metadata": {},
   "source": [
    "# 5. Send command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "522ad641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(base) [rh183@login02 ~]$ \n",
      "aceRhythm/dispatcher.pyurobio/sabatini/rich/analysis/f \n",
      "\n",
      "python3: can't open file '/n/data1/hms/neurobio/sabatini/rich/analysis/faceRhythm/dispatcher.py': [Errno 2] No such file or directory\n",
      "(base) [rh183@login02 ~]$ \n",
      "\n",
      "(base) [rh183@login02 ~]$ \n"
     ]
    }
   ],
   "source": [
    "ssh_c.send_receive('', timeout=1, verbose=True)\n",
    "ssh_c.send(runFile['command'])\n",
    "recv_command = ssh_c.expect(str_success=f\"[{runFile['o2_acct']}\", total_timeout=1)\n",
    "ssh_c.send_receive('', timeout=1, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3689eb",
   "metadata": {},
   "source": [
    "# 6. Log `.json` run file contents to `.csv` logger file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e33ebc",
   "metadata": {},
   "source": [
    "download master copy of `logger.csv` file from remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d98da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logger(path_logger):\n",
    "    return pd.read_csv(\n",
    "        filepath_or_buffer=path_logger,\n",
    "#         sep=NoDefault.no_default,\n",
    "        delimiter=None, \n",
    "        header='infer', \n",
    "#         names=NoDefault.no_default,\n",
    "        index_col=None,\n",
    "        usecols=None,\n",
    "        squeeze=None,\n",
    "#         prefix=NoDefault.no_default,\n",
    "        mangle_dupe_cols=True,\n",
    "        dtype=None, \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f0dfc",
   "metadata": {},
   "source": [
    "Add a couple things to make an augmented version of the runFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca08e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "runFile_aug = copy.deepcopy(runFile)\n",
    "runFile_aug['time_run'] = time.ctime()\n",
    "runFile_aug['datetime_Ymd_HMS_f'] = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "runFile_aug['cmd_receipt'] = recv_command[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0150a",
   "metadata": {},
   "source": [
    "try to find the logger on remote and download it. if it's there, append the augmented runFile to it. if its not there, make a new local one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d9f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found and downloaded remote copy of logger. from:  /n/data1/hms/neurobio/sabatini/serverteeny/logger/logger_serverteeny.csv  to:  /media/rich/bigSSD/tmp_data/serverteeny_tmpFiles/logger_serverteeny.csv\n",
      "appended run file dictionary to local copy of logger\n",
      "uploaded updated or new logger file to remote\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sftp.sftp.get(\n",
    "        remotepath=path_loggerCsv_remote,\n",
    "        localpath=path_loggerCsv_local,\n",
    "    )  ## note that when this fails, it still makes an empty local file with the correct path    \n",
    "    print(f'found and downloaded remote copy of logger. from:  {path_loggerCsv_remote}  to:  {path_loggerCsv_local}')\n",
    "    \n",
    "    logger = pd.read_csv(filepath_or_buffer=path_loggerCsv_local)\n",
    "    pd.DataFrame(runFile_aug, index=[logger.shape[0]]).to_csv(path_loggerCsv_local, mode='a', header=False) ## append the new augmented runFile to the end of it. make the index the existing number of entries in the logger\n",
    "    print(f'appended run file dictionary to local copy of logger')\n",
    "    \n",
    "except:\n",
    "    print(f'Failed to retrieve logger from remote. Making new one here:  {path_loggerCsv_local}')\n",
    "\n",
    "    pd.DataFrame(runFile_aug, index=[0]).to_csv(path_loggerCsv_local, mode='w')  ## write a new logger\n",
    "\n",
    "## upload the updated or new logger file to remote\n",
    "sftp.sftp.put(\n",
    "    localpath=path_loggerCsv_local,\n",
    "    remotepath=path_loggerCsv_remote,\n",
    ");\n",
    "print(f'uploaded updated or new logger file to remote')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf6253",
   "metadata": {},
   "source": [
    "# 7. Send email with run file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f440607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_str(dictionary):\n",
    "    return '\\n'.join([f'{key}:  {val}' for key,val in dictionary.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cac9306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "b''\n",
      "Server: nginx\n",
      "Date: Sat, 04 Jun 2022 09:08:28 GMT\n",
      "Content-Length: 0\n",
      "Connection: close\n",
      "X-Message-Id: 7PA3yMXyRd-Sl8YPVOx2dg\n",
      "Access-Control-Allow-Origin: https://sendgrid.api-docs.io\n",
      "Access-Control-Allow-Methods: POST\n",
      "Access-Control-Allow-Headers: Authorization, Content-Type, On-behalf-of, x-sg-elas-acl\n",
      "Access-Control-Max-Age: 600\n",
      "X-No-CORS-Reason: https://sendgrid.com/docs/Classroom/Basics/API/cors.html\n",
      "Strict-Transport-Security: max-age=600; includeSubDomains\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if pref_sendEmail:\n",
    "#     email_body = \n",
    "    sender = email_helpers.Sender(api_key='')\n",
    "    sender.send(\n",
    "            from_email='serverteeny@gmail.com', \n",
    "            to_emails ='serverteeny@gmail.com', \n",
    "            subject='Run log', \n",
    "            content=dict_to_str(runFile_aug),\n",
    "            verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c6cf4",
   "metadata": {},
   "source": [
    "# 8. Delete the remote `.json` run file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f69db70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted remote .json run file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sftp.sftp.remove(path_runFile_remote)\n",
    "    print('deleted remote .json run file')\n",
    "except:\n",
    "    print(\"couldn't delete remote .json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e3cf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_c.close()\n",
    "del ssh_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c24b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5545c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d0581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eef80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d320043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
